for (outvar in outvars) {
scaler = switch (outvar,
"c_ResponseCorrect" = 100,
"alphapwr_diff_retent" = 1e12,
"maxDecodScoreTime_sensorspace" = 1000,
"maxDecodScoreTime_csp" = 1000,
1
)
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
task_print <- if_else(task == "exp", "vSTM", "perception")
print("#####################################################")
print(str_glue("####  TASK: {task_print}"))
print("#####################################################")
# Summary accuracy overall:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop"
) %>%
ungroup() %>%
select(!ppid)
# Here we cannot calculate Cousineau-Morey CIs, so we take normal CIs:
acc_overall[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
rm(tmp)
stats_overall[[task]][[outvar]] <- list(
name = "overall",
printName = "overall",
levels = c(""),
stats = acc_overall[[task]][[outvar]]
)
# Summary per Memory Load:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_") %>%
ungroup() %>%
select(!ppid)
acc_per_memLoad[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_memLoad[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_memLoad[[task]][[outvar]] <- list(
name = "StimN",
printName = "memLoad",
levels = str_c("StimN_", unique(data_behav_per_task[[task]]$c_StimN), '_'),
stats = acc_per_memLoad[[task]][[outvar]]
)
# Summary per Ecc:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_") %>%
ungroup() %>%
select(!ppid)
acc_per_ecc[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_ecc[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_ecc[[task]][[outvar]] <- list(
name = "ecc",
printName = "Ecc",
levels = str_c("Ecc_", sort(unique(data_behav_per_task[[task]]$c_Ecc)), '_'),
stats = acc_per_ecc[[task]][[outvar]]
)
print("       **********************************************")
print(str_glue("       ******  Dep. varibale: {outvar}"))
print("       **********************************************")
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
print(str_glue("DV ({if_else(str_detect(tmp$printName, 'overall'), '', 'by ')}{tmp$printName}):\n"))
for (lvl in tmp$levels) {
if (length(tmp$levels) > 1) print(str_glue("{tmp$printName} == {parse_number(lvl)}:"))
print(str_glue("    mean  (%): {tmp$stats[str_c(lvl, 'mean')]}"))
print(str_glue("    SD    (%): {tmp$stats[str_c(lvl, 'sd')]}"))
print(str_glue("    min   (%): {tmp$stats[str_c(lvl, 'min')]}"))
print(str_glue("    max   (%): {tmp$stats[str_c(lvl, 'max')]}"))
print(str_glue("    95% CI(%): {tmp$stats[str_c(lvl, 'ci95lower')]} - {tmp$stats[str_c(lvl, 'ci95upper')]}"))
if (tmp$name != "overall") {
print(str_glue("    95% Cousineau-Morey CI(%): {tmp$stats[str_c(lvl, 'cmci95lower')]} - {tmp$stats[str_c(lvl, 'cmci95upper')]}"))
}
}
cat("\n\n")
}
## Pairwise differences of the mean (with regular CIs):
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_",
id_cols = ppid) %>%
mutate(diff = StimN_2 - StimN_4) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean, sd=sd, ci95lower=ci95lower, ci95upper=ci95upper))
print("Difference between Memory Load conditions:")
print(str_glue("  Mean (CI):     {format(tmp_df$diff_mean, digits=3)} ({format(tmp_df$diff_ci95lower, digits=3)} - {format(tmp_df$diff_ci95upper, digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_mean"), tmp_df$diff_mean, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_cilower"), tmp_df$diff_ci95lower, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_ciupper"), tmp_df$diff_ci95upper, exp_format="%.2f")
cat("\n\n")
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_",
id_cols = ppid) %>%
mutate(diff_Ecc4vsEcc9 = Ecc_4 - Ecc_9,
diff_Ecc4vsEcc14 = Ecc_4 - Ecc_14,
diff_Ecc9vsEcc14 = Ecc_9 - Ecc_14) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean,
sd=sd,
ci95lower=ci95lower,
ci95upper=ci95upper,
t_stat_t= ~ summarize_ttest(x = ., returnval = "t"),
t_stat_p= ~ summarize_ttest(x = ., returnval = "p")))
print("Difference between Eccentricity conditions:")
contrast_pairs <- list(c("4", "9"), c("4", "14"), c("9", "14"))
for (cp in contrast_pairs) {
print(str_glue("  Contrast: {cp[1]} - {cp[2]}"))
print(str_glue(".    Mean (%):     {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], digits=3)}
.    CI (%):       ({format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], digits=3)} - {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_mean"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_cilower"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_ciupper"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_t"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_t')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_p"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_p')]], exp_format="%.3f", is_pval = TRUE)
}
cat("\n\n")
}
}
extract_var("n_rej_subs", n_rej_subs, exp_format = "%i")
extract_var("n_tot_trials_prerej_allsubs", 720 * (n_subs_analyzed + n_rej_subs), exp_format = "%i")
extract_var("n_subs_analyzed", n_subs_analyzed, exp_format = "%i")
extract_var("n_tot_trials_prerej", n_tot_trials_prerej, exp_format = "%i")
extract_var("n_trials_rejected", n_tot_trials_prerej - n_tot_trials_postrej, exp_format = "%i")
extract_var("n_tot_trials_postrej", n_tot_trials_postrej, exp_format = "%i")
extract_var("avg_n_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%.2f")
extract_var("min_n_trials_per_sub_postrej", min(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("max_n_trials_per_sub_postrej", max(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("avg_perc_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("min_perc_trials_per_sub_postrej", min(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("max_perc_trials_per_sub_postrej", max(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
for(task in c("exp", "perc")) {
if (task == "exp") {
outvars <- list("c_ResponseCorrect",
"dprime",
"CDA_amp_clustertimes",
"PNP_amp_clustertimes",
"alphapwr_diff_retent",
"maxDecodScore_sensorspace",
"maxDecodScoreTime_sensorspace",
"maxDecodScore_csp",
"maxDecodScoreTime_csp")
} else {
outvars <- list("c_ResponseCorrect", "dprime")
}
for (outvar in outvars) {
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
for (lvl in tmp$levels) {
for (stat in c("mean", "sd", "min", "max", "ci95lower", "ci95upper", "cmci95lower", "cmci95upper")) {
# for the grand average, we skip the Cousineau-Morey CIs (as we could not calculate them):
if (tmp$name == "overall" && str_detect(stat, "cmci")) {
next
}
extract_var(str_glue("{dv_str}_{task}_{lvl}{stat}"), tmp$stats[str_c(lvl, stat)], exp_format="%.2f")
}
}
}
}
}
# Code to chunk:
insert_fun("func_analysis_01")
# VSTM task:
results_anova_behav_exp <- func_analysis_01('experiment')
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
extract_var(str_c("anova_behav_exp_eff_", eff_print, "_F"), summary(results_anova_behav_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_behav_exp_eff_", eff_print, "_df_within"), summary(results_anova_behav_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_exp_eff_", eff_print, "_df_resid"), summary(results_anova_behav_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_exp_eff_", eff_print, "_p"), summary(results_anova_behav_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
# perceptual Change Detection Task:
results_anova_behav_perc <- func_analysis_01('perception')
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
extract_var(str_c("anova_behav_perc_eff_", eff_print, "_F"), summary(results_anova_behav_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_behav_perc_eff_", eff_print, "_df_within"), summary(results_anova_behav_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_perc_eff_", eff_print, "_df_resid"), summary(results_anova_behav_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_perc_eff_", eff_print, "_p"), summary(results_anova_behav_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
# VSTM task:
results_anova_behav_dprime_exp <- func_analysis_01.1('experiment')
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
extract_var(str_c("anova_behav_dprime_exp_eff_", eff_print, "_F"), summary(results_anova_behav_dprime_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_behav_dprime_exp_eff_", eff_print, "_df_within"), summary(results_anova_behav_dprime_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_dprime_exp_eff_", eff_print, "_df_resid"), summary(results_anova_behav_dprime_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_dprime_exp_eff_", eff_print, "_p"), summary(results_anova_behav_dprime_exp$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
extract_var(str_c("anova_behav_dprime_perc_eff_", eff_print, "_F"), summary(results_anova_behav_dprime_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_behav_dprime_perc_eff_", eff_print, "_df_within"), summary(results_anova_behav_dprime_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_dprime_perc_eff_", eff_print, "_df_resid"), summary(results_anova_behav_dprime_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_behav_dprime_perc_eff_", eff_print, "_p"), summary(results_anova_behav_dprime_perc$aov.srt)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
# VSTM task:
func_analysis_03('experiment')
# perceptual Change Detection Task:
func_analysis_03('perception')
results_anova_cda <- func_analysis_05(dep_variable = "CDA_amp_clustertimes")
# Code to chunk:
insert_fun("func_analysis_05")
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
# TODO: it's really ugly to split up the exports between here and the function call. I feel bad but will change this only in future projects.
extract_var(str_c("anova_cda_eff_", eff_print, "_F"), summary(results_anova_cda)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_cda_eff_", eff_print, "_df_within"), summary(results_anova_cda)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_cda_eff_", eff_print, "_df_resid"), summary(results_anova_cda)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_cda_eff_", eff_print, "_p"), summary(results_anova_cda)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
m1 <- func_analysis_07('experiment', dep_variable = 'CDA_amp_clustertimes')
print(summary(m1))
summary_df <- data.frame(coef(summary(m1)))
ci_df <- print_CI_lmer(m1)
summary_df <- merge(summary_df, ci_df, by = 0)
summary_df[, -c(1, 6)] <- round(summary_df[, -c(1, 6)], 2)
# round p-value to 3 digits:
summary_df[, 6] <- round(summary_df[, 6], 3)
summary_df$ci_formatted <- sprintf("[%.2f; %.2f]", summary_df$lower, summary_df$upper)
print(summary_df)
# Code to chunk:
insert_fun("func_analysis_07")
results_anova_cda_fixedtimes <- func_analysis_05(dep_variable = "CDA_amp_fixedtimes")
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
# TODO: it's really ugly to split up the exports between here and the function call. I feel bad but will change this only in future projects.
extract_var(str_c("anova_cda_fixedtimes_eff_", eff_print, "_F"), summary(results_anova_cda_fixedtimes)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_cda_fixedtimes_eff_", eff_print, "_df_within"), summary(results_anova_cda_fixedtimes)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_cda_fixedtimes_eff_", eff_print, "_df_resid"), summary(results_anova_cda_fixedtimes)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_cda_fixedtimes_eff_", eff_print, "_p"), summary(results_anova_cda_fixedtimes)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
m1 <- func_analysis_07('experiment', dep_variable = 'CDA_amp_fixedtimes')
print(summary(m1))
summary_df <- data.frame(coef(summary(m1)))
ci_df <- print_CI_lmer(m1)
summary_df <- merge(summary_df, ci_df, by = 0)
summary_df[, -c(1, 6)] <- round(summary_df[, -c(1, 6)], 2)
# round p-value to 3 digits:
summary_df[, 6] <- round(summary_df[, 6], 3)
summary_df$ci_formatted <- sprintf("[%.2f; %.2f]", summary_df$lower, summary_df$upper)
print(summary_df[, c(1, 2, 5, 4, 9, 6, 3, 7, 8)])
results_anova_pnp <- func_analysis_09(dep_variable = "PNP_amp_clustertimes")
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
extract_var(str_c("anova_pnp_eff_", eff_print, "_F"), summary(results_anova_pnp)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_pnp_eff_", eff_print, "_df_within"), summary(results_anova_pnp)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_pnp_eff_", eff_print, "_df_resid"), summary(results_anova_pnp)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_pnp_eff_", eff_print, "_p"), summary(results_anova_pnp)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
results_anova_alphalat <- func_analysis_06()
# Code to chunk:
insert_fun("func_analysis_06")
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
eff_print <- eff %>%
str_replace_all("c_", "") %>%
str_replace_all(":", "x")
extract_var(str_c("anova_alphalat_eff_", eff_print, "_F"), summary(results_anova_alphalat)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
extract_var(str_c("anova_alphalat_eff_", eff_print, "_df_within"), summary(results_anova_alphalat)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]],
exp_format = "%i")
extract_var(str_c("anova_alphalat_eff_", eff_print, "_df_resid"), summary(results_anova_alphalat)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
exp_format = "%i")
extract_var(str_c("anova_alphalat_eff_", eff_print, "_p"), summary(results_anova_alphalat)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]],
is_pval = TRUE,
exp_format = "%.3f")
}
func_analysis_10('experiment', dep_variable = 'alpha_pwr')
results_anova_globalpha <- func_analysis_06.1()
results_anova_rejtrials <- func_analysis_16()
source(file.path(here('Utils', 'load_functions.R')))
results_anova_rejtrials <- func_analysis_16()
source(file.path(here('Utils', 'load_functions.R')))
results_anova_rejtrials <- func_analysis_16()
results_anova_rejtrials <- func_analysis_16()
results_anova_rejtrials <- func_analysis_16()
? hypot
#--------------------------------------------------------------------------
# ET Utils
#
# Helper functions for the eye tracking analyses
#--------------------------------------------------------------------------
require(tidyverse)
require(usethis)
require(pracma)
require(zoo)
get_blink_frames <- function(df_blink) {
dd <- df_blink %>%
group_by(n = row_number()) %>%
do(data.frame(blink_frames = seq(from = .$start_frame_index, to = .$end_frame_index))) %>%
ungroup() %>%
dplyr::select(blink_frames) %>%
as_vector()
return(dd)
}
normalize_vec <- function(x) {x / sqrt(sum(x^2))}
cart2sph_custom <- function (xyz) {
# ' Convert cartesian coordinates (xyz) to spherical coordinates (theta-phi-r) with the zenith being at the positve end of z
# ' (in a left handed coordinate system with z going into depth!).
# '
# ' @param xyz Vector with x-y-z coordinates. Or matrix with shape nx3 cols: x-y-z)
# ' @return A vector/matrix with the elements/columns: theta (azimuth), phi (inclination), and r (dist to origin).
stopifnot(is.numeric(xyz))
if (is.vector(xyz) && length(xyz) == 3) {
x <- xyz[1]
y <- xyz[2]
z <- xyz[3]
m <- 1
}
else if (is.matrix(xyz) && ncol(xyz) == 3) {
x <- xyz[, 1]
y <- xyz[, 2]
z <- xyz[, 3]
m <- nrow(xyz)
}
else stop("Input must be a vector of length 3 or a matrix with 3 columns.")
hypotxz <- hypot(x, z)
r <- hypot(y, hypotxz)
phi <- atan2(y, hypotxz) * -1    #multiply with -1 to correct the sign to fit the left handed coordinate system used by the ET/Unity
theta <- atan2(x, z)
if (m == 1)
tpr <- c(theta, phi, r)
else tpr <- cbind(theta, phi, r)
return(tpr)
}
translate_xyz2spherical <- function(df, x_col, y_col, z_col, prefix_output) {
x_col <- enquo(x_col)
y_col <- enquo(y_col)
z_col <- enquo(z_col)
res <- df %>%
add_column(!!str_c(prefix_output, '_theta') := rad2deg(cart2sph_custom(as.matrix(select(., !! x_col, !! y_col, !! z_col)))[, 1])) %>%
add_column(!!str_c(prefix_output, '_phi')   := rad2deg(cart2sph_custom(as.matrix(select(., !! x_col, !! y_col, !! z_col)))[, 2])) %>%
add_column(!!str_c(prefix_output, '_r')     :=         cart2sph_custom(as.matrix(select(., !! x_col, !! y_col, !! z_col)))[, 3])
return(res)
}
spline_interpolate_low_conf_samples <- function(vec,
conf_vec,
conf_threshold,
margin = 20,
maxgap = 100) {
if (!typeof(vec) == 'double') {
warning(paste('Expected type "double" but got type: ',
typeof(vec)))
}
margin_start <- vec[1:margin]
margin_end <- vec[(length(vec)-margin+1):length(vec)]
vec_trimmed <- vec[(margin+1):(length(vec)-margin)]
conf_vec_trimmed <- conf_vec[(margin+1):(length(vec)-margin)]
vec_trimmed[conf_vec_trimmed < conf_threshold] <- NA_real_
vec_concat <- c(margin_start, vec_trimmed, margin_end)
vec_spline <- na.approx(vec_concat,
maxgap = maxgap,
na.rm = FALSE)
if (sum(is.na(vec_spline)) > 2*margin) {
na_idx <- which(is.na(vec_spline))
vec_spline[na_idx] <- vec[na_idx]
warning('There were stretches of low confidence longer
than the max gap allowed. Leaving original values
for these.')
}
#vec_out <- c(margin_start, vec_spline, margin_end)
return(vec_spline)
}
et_resample <- function(df, var_time, srate, tmax = NULL, tmin = NULL) {
# ' Resample to fixed sampling rate, keeping only sample with highest confidence
# '
# ' @param df Dataframe or tibble with eye tracking data as output by `\Analyses_R\EyeTracking\extract_data_to_rds.R`.
#             Normally you'll want to hand over a grouped df (by ID, trial, ...).
# ' @param var_time (character) Name of the column in the df that contains the original time stamps of the samples.
# ' @param srate (int) Targeted sampling rate.
# ' @param tmin/tmax (double) Start/End time of the interval which shall be extracted and resampled.
# ' @return A vector/matrix with the elements/columns: theta (azimuth), phi (inclination), and r (dist to origin).
if (!is_null(tmax)) {
df <- df %>%
filter(get(var_time) <= tmax + (1/srate)/2)
} else
{
tmax <- df$'var_time'[length(df$'var_time')]
}
if (!is_null(tmin)) {
df <- df %>%
filter(get(var_time) >= tmin - (1/srate)/2)
} else
{
tmin <- df$'var_time'[1]
}
times <- seq(tmin, tmax, 1/srate)
df_resampled <- df %>%
mutate(time_resampled = sapply(gaze_timestamp, findindx, times)) %>%
group_by(time_resampled, .add = T) %>%
mutate(max_conf_ = max(confidence)) %>%
filter(confidence == max_conf_) %>%
select(!max_conf_) %>%
ungroup(time_resampled) %>%
distinct(time_resampled, .keep_all = TRUE)
return(df_resampled)
}
findindx <- function(vec, ttimes) {
out <- ttimes[which.min(abs(vec - ttimes))]
return(out)
}
# dir helper:
checkmake_dirs <- function(paths) {
for (path in paths) {
if (!dir.exists(path)) {
dir.create(path)
ui_info(str_c("Created dir: {path}"))
}
}
}
cart2sph_custom(c(1,2,3))
atan2(1,2)
atan2(1,-2)
atan2(-1,-2)
