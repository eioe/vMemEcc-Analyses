ungroup() %>%
select("dprime", "c_StimN", "c_Ecc", "ppid")
c1.reduced <- c1.aov %>%
pivot_wider(names_from = c(c_StimN, c_Ecc),
values_from = dprime,
names_prefix = 'cond_') %>%
select(., contains('cond_'))
ci_cm <- cm.ci(data.frame=c1.reduced,
conf.level=2*(pnorm(1,0,1)-0.5),
difference=TRUE) #1sem or 1.96sem
#--------------------------------------------------------------------------
## Run ANOVA
aov.srt <- aov(dprime ~ c_StimN*c_Ecc + Error(ppid/(c_StimN* c_Ecc)),data=c1.aov)
results = list()
results[["aov.srt"]] <- aov.srt
print_header(str_c('Summary ANOVA \ntask: ', condition))
print(summary(aov.srt))
## rstatix alternative (identical results:)
# aov.res <- anova_test(data = c1.aov,
#                       dv = meanAcc,
#                       wid = ppid,
#                       within = c(c_StimN, c_Ecc))
# get_anova_table(aov.re  s)
#--------------------------------------------------------------------------
## Run post-hoc t tests:
# main effect Eccentricity:
res_ttest <- data2analyze %>%
filter(BlockStyle == condition) %>%
group_by(ppid, c_Ecc) %>%
summarise(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
ungroup() %>%
pairwise_t_test(
dprime ~ c_Ecc, paired = TRUE,
p.adjust.method = "bonferroni",
detailed = TRUE
)
print_header(str_c('Results post-hoc t test\ntask: ', condition))
print(res_ttest)
results[["res_ttest"]] <- res_ttest
# means <- data2analyze %>%
#   filter(BlockStyle == condition) %>%
#   select(c_Ecc, ppid, c_ResponseCorrect) %>%
#   group_by(c_Ecc, ppid) %>%
#   pivot_wider(id_cols =  ppid, names_from = c_Ecc, values_from = c_ResponseCorrect, values_fn = mean) %>%
#   ungroup() %>%
#   select(!ppid) %>%
#   summarise_all(.funs = c(mean))
# print(means)
#--------------------------------------------------------------------------
## Plot
c1.plt <- c1.aov %>%
group_by(c_StimN, c_Ecc) %>%
summarise(meandprime = mean(dprime)) %>%
mutate(cond = str_c('cond', c_StimN, c_Ecc, sep = '_'),
c_Ecc = as.numeric(as.character(c_Ecc))) %>%
left_join(as_tibble(ci_cm) %>%
add_column(cond = rownames(ci_cm)),
by = 'cond')
txt_title <- ifelse(condition == 'perception',
'Perceptual Task',
'VSTM Task')
figa <- ggplot(c1.plt,
aes(x = c_Ecc,
y = meandprime,
ymin = lower,
ymax = upper,
colour = as_factor(c_StimN))) #+ facet_wrap(~cond)
#figa <- figa + geom_jitter(position=position_jitter(width=100))
figa <- figa + geom_line(size=0.2358491) + geom_point(shape=15,size=0.1)
figa <- figa + scale_colour_manual(values=c(col_LoadLow, col_LoadHigh, defgrey))  # values=c(defblue,deforange,defgrey))
figa <- figa + scale_fill_manual(values=c(defblue,deforange,defgrey))
figa <- figa + geom_linerange(size=0.2358491)
figa <- figa + scale_x_continuous(breaks=c(4,9,14))
figa <- figa + scale_y_continuous(limits=c(0.0, 2.5))
figa <- figa + mytheme
figa <- figa + ylab("Proportion correct") + xlab("Eccentricity")
# figa <- figa + labs(title = txt_title, color = "Size Memory Array")
figa <- figa + theme(legend.position = c(1.85, 1.15))
plot(figa)
fname = file.path(path_global, 'Plots2022', 'Behavior', str_c('behav_dprime_perf_anova_', condition, '.pdf'))
ggsave(plot = figa,
width = 5/2.54,
height = 3.7/2.54,
dpi = 300,
filename = fname)
#--------------------------------------------------------------------------
return(results)
}
#--------------------------------------------------------------------------
# Is there an interaction effect of trial type (VSTM vs Perception) with
# load or eccentricity on accuracy?
#
#--------------------------------------------------------------------------
#
# func_analysis_01a <- function(dep_variable) {
#
#   # Drop trials where we do not have EEG data:
#   if (condition == "experiment") {
#     data2analyze <- data_behav %>%
#       drop_na()
#   } else {
#     data2analyze <- data_behav
#   }
#
#   ## Select relevant data:
#   data_filtered <- data2analyze %>%
#     select(ppid, c_StimN, c_Ecc, c_ResponseCorrect, BlockStyle) %>%
#     mutate(c_Ecc = as_factor(c_Ecc),
#            c_BlockStyle = as_factor(BlockStyle))
#
#   # Define contrast - baseline is Eccentricity = 9Â° and MemLoad = 2 and BlockStyle = experiment
#   contrasts(data_filtered$c_Ecc) <- contr.treatment(3,base=2)
#   data_filtered$load_contrast <- ifelse(data_filtered$c_StimN==2,1,0)
#   data_filtered$BS_contrast <- ifelse(data_filtered$BlockStyle=='experiment',0,1)
#
#
#   #--------------------------------------------------------------------------
#   ## run glmer
#
#   glmer.family = ifelse(dep_variable == 'c_ResponseCorrect',
#                         'binomial',
#                         'gaussian')
#
#   m1 <- glmer(c_ResponseCorrect ~ load_contrast*c_Ecc*BS_contrast + (1|ppid),
#               data = data_filtered,
#               family = "binomial")
#
#   print_header(str_c('Summary glmer\n',
#                      dep_variable, ' ~ MemLoad * Eccentricity * BlockStyle\n'))
#   print(summary(m1))
#   print(Anova(m1))
#
#
#
#
#
#   ## Plot it:
#
#   c1.aov <- data2analyze %>%
#     mutate(BlockStyle = recode(BlockStyle, 'experiment' = 'memory')) %>%
#     group_by(ppid, c_StimN, c_Ecc, BlockStyle) %>%
#     summarise(meanAcc = mean(c_ResponseCorrect)) %>%
#     ungroup() %>%
#     select("meanAcc", "c_StimN", "c_Ecc", "ppid", "BlockStyle")
#
#   c1.reduced <- c1.aov %>%
#     pivot_wider(names_from = c(c_StimN, c_Ecc, BlockStyle),
#                 values_from = meanAcc,
#                 names_prefix = 'cond_') %>%
#     select(., contains('cond_'))
#
#   ci_cm <- cm.ci(data.frame=c1.reduced,
#                  conf.level=2*(pnorm(1,0,1)-0.5),
#                  difference=TRUE) #1sem or 1.96sem
#
#
#   c1.plt <- c1.aov %>%
#     mutate(c_Ecc = as.numeric(as.character(c_Ecc))) %>%
#     group_by(c_StimN, c_Ecc, BlockStyle) %>%
#     summarise(meanAcc = mean(meanAcc)) %>%
#     mutate(cond = str_c('cond', c_StimN, c_Ecc, BlockStyle, sep = '_')) %>%
#     left_join(as_tibble(ci_cm) %>%
#                 add_column(cond = rownames(ci_cm)),
#               by = 'cond')
#
#   txt_title <- 'Task comparison'
#
#   figa <- ggplot(c1.plt,
#                  aes(x = c_Ecc,
#                      y = meanAcc,
#                      ymin = lower,
#                      ymax = upper,
#                      colour = as_factor(c_StimN))) + facet_wrap(~BlockStyle)
#   #figa <- figa + geom_jitter(position=position_jitter(width=100))
#   figa <- figa + geom_line(size=0.2358491) + geom_point(shape=15,size=0.8)
#   figa <- figa + scale_colour_manual(values=c(col_LoadLow, col_LoadHigh, defgrey))  #  values=c(defblue,deforange,defgrey))
#   figa <- figa + scale_fill_manual(values=c(defblue,deforange,defgrey))
#   figa <- figa + geom_linerange(size=0.2358491)
#   figa <- figa + scale_x_continuous(breaks=c(4,9,14))
#   figa <- figa + scale_y_continuous(limits=c(0.5,1.0))
#   figa <- figa + mytheme
#   figa <- figa + ylab("Proportion correct") + xlab("Eccentricity")
#   figa <- figa + labs(title = txt_title, color = "Array Size")
#   figa <- figa + theme(legend.position = c(0.85, 0.15))
#
#
#   figa
#
#  }
func_analysis_01.1("experiment")
func_analysis_01.1("perception")
func_analysis_01.1("perception")
ha <- func_analysis_01.1("perception")
ha
ha <- func_analysis_01.1("experiment")
means <- data2analyze %>%
filter(BlockStyle == condition) %>%
select(c_Ecc, ppid, c_ResponseCorrect) %>%
group_by(c_Ecc, ppid) %>%
summarise(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
pivot_wider(id_cols =  ppid, names_from = c_Ecc, values_from = dprime, values_fn = mean) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean))
print(means)
means <- data2analyze %>%
filter(BlockStyle == condition) %>%
select(c_Ecc, ppid, hit, FalseAlarm) %>%
group_by(c_Ecc, ppid) %>%
summarise(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
pivot_wider(id_cols =  ppid, names_from = c_Ecc, values_from = dprime, values_fn = mean) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean))
print(means)
means <- data2analyze %>%
filter(BlockStyle == condition) %>%
select(c_Ecc, ppid, Hit, FalseAlarm) %>%
group_by(c_Ecc, ppid) %>%
summarise(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
pivot_wider(id_cols =  ppid, names_from = c_Ecc, values_from = dprime, values_fn = mean) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean))
print(means)
data2analyze %>%
filter(BlockStyle == condition) %>%
select(c_Ecc, ppid, Hit, FalseAlarm) %>%
group_by(c_Ecc, ppid) %>%
summarise(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
pivot_wider(id_cols =  ppid, names_from = c_Ecc, values_from = dprime, values_fn = mean)
knitr::opts_chunk$set(echo = TRUE)
#--------------------------------------------------------------------------
# Run main script for analysis for:
#  vMemEcc
#--------------------------------------------------------------------------
library(here)
library(knitr)
#--------------------------------------------------------------------------
# Define pathes
path_global 	    <- here('../..')
path_r_data       <- file.path(path_global, 'Data/DataR')
path_scripts_sven <- file.path(here('Workflow_Sven',
'osf_experiment1',
'_RScripts'))
path_extracted_vars <- file.path(here('../VME_extracted_vars.json'))
# path_global, 'Writing',
#                            'Other',
#                            'VME_extracted_vars.json')
#--------------------------------------------------------------------------
## load packages & custom utils:
source(here("Utils", "load_packages.R"))
source(here('Utils', 'print_output.R'))
source(here('Utils', 'utils_report.R'))
source(here('Utils', 'calc_conf_intervalls.R'))
#--------------------------------------------------------------------------
#--------------------------------------------------------------------------
## define colors
source(file.path(path_scripts_sven, "loadColors.R"))
#--------------------------------------------------------------------------
#--------------------------------------------------------------------------
## load function to compute confidence intervals
source(file.path(path_scripts_sven,"loadFunctions.R"))
source(file.path(here('Utils', 'load_functions.R')))
#--------------------------------------------------------------------------
#--------------------------------------------------------------------------
## load theme
source(file.path(path_scripts_sven, "loadTheme.R"))
#--------------------------------------------------------------------------
#--------------------------------------------------------------------------
## load data, assign names for columns and define variable type
source(file.path(here('Utils', 'load_data.R')))
#--------------------------------------------------------------------------
# Write
extract_var("r_version", "v4.1.0", exp_format = "%s")
extract_var("rstudio_version", "v1.4.1717", exp_format = "%s")
# Total number of experimental trials (720 x n):
n_rej_subs <- 3
print(str_glue("N rejected subjects: {n_rej_subs}"))
n_subs_analyzed <- length(unique(data_behav$ppid))
n_tot_trials <- 720 * (n_subs_analyzed + n_rej_subs)
n_tot_trials_prerej <- 720 * n_subs_analyzed
print(str_glue("Total number of recorded experimental trials (720 x {n_subs_analyzed + n_rej_subs}): {n_tot_trials}"))
print(str_glue("Total number of experimental trials after subject rejection (720 x {n_subs_analyzed}): {n_tot_trials_prerej}"))
n_tot_trials_postrej <- data_behav %>% filter(BlockStyle == 'experiment') %>%  drop_na() %>% nrow()
n_trials_rejected <- n_tot_trials_prerej - n_tot_trials_postrej
print(str_glue("Total number of trials after rejection: {n_tot_trials_postrej} ({n_trials_rejected} trials rejected)"))
data_behav_per_task <- vector(mode = "list", length = 2)
data_behav_per_task[['exp']] <- data_behav %>%
filter(BlockStyle == 'experiment') %>%
drop_na() %>%
group_by(ppid) %>%
mutate(dprime = qnorm(mean(Hit)) - qnorm(mean(FalseAlarm))) %>%
ungroup()
data_behav_per_task[['perc']] <- data_behav %>%
filter(BlockStyle == 'perception') %>%
# select(!contains(c('CDA_amp', 'PNP_amp', 'alphapwr_diff_retent'))) %>%
select(ppid, trial_num, block_num, c_StimN, c_Ecc, c_ResponseCorrect, c_ResponseTime, BlockStyle, Hit, FalseAlarm, CorrRej, Miss) %>%
drop_na() %>%
group_by(ppid) %>%
mutate(dprime = qnorm(mean(Hit)) - qnorm(mean(FalseAlarm))) %>%
ungroup()
# Summary remaining trials:
summary_rem_trials_per_sub <- data_behav_per_task[['exp']] %>%
group_by(ppid) %>%
summarise(n_trials_remaining = n(),
perc_trials_remaining = n_trials_remaining*100 / 720,
.groups = "drop")
print(str_glue("Remaining trials per subject (percentage):
mean: {mean(summary_rem_trials_per_sub$n_trials_remaining)} ({format(mean(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%)
range:  {min(summary_rem_trials_per_sub$n_trials_remaining)} ({format(min(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%) - {max(summary_rem_trials_per_sub$n_trials_remaining)} ({format(max(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%)\n\n"))
acc_overall <- vector(mode = "list", length = 2)
stats_overall <- vector(mode = "list", length = 2)
acc_per_memLoad <- vector(mode = "list", length = 2)
stats_memLoad <- vector(mode = "list", length = 2)
acc_per_ecc <- vector(mode = "list", length = 2)
stats_ecc <- vector(mode = "list", length = 2)
for (task in c('perc', 'exp')) {
if (task == "exp") {
outvars <- list("c_ResponseCorrect",
"dprime",
"CDA_amp_clustertimes",
"PNP_amp_clustertimes",
"alphapwr_diff_retent",
"maxDecodScore_sensorspace",
"maxDecodScoreTime_sensorspace",
"maxDecodScore_csp",
"maxDecodScoreTime_csp")
} else {
outvars <- list("c_ResponseCorrect",
"dprime")
}
for (outvar in outvars) {
scaler = switch (outvar,
"c_ResponseCorrect" = 100,
"alphapwr_diff_retent" = 1e12,
"maxDecodScoreTime_sensorspace" = 1000,
"maxDecodScoreTime_csp" = 1000,
1
)
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
task_print <- if_else(task == "exp", "vSTM", "perception")
print("#####################################################")
print(str_glue("####  TASK: {task_print}"))
print("#####################################################")
# Summary accuracy overall:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop"
) %>%
ungroup() %>%
select(!ppid)
# Here we cannot calculate Cousineau-Morey CIs, so we take normal CIs:
acc_overall[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
rm(tmp)
stats_overall[[task]][[outvar]] <- list(
name = "overall",
printName = "overall",
levels = c(""),
stats = acc_overall[[task]][[outvar]]
)
# Summary per Memory Load:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_") %>%
ungroup() %>%
select(!ppid)
acc_per_memLoad[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_memLoad[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_memLoad[[task]][[outvar]] <- list(
name = "StimN",
printName = "memLoad",
levels = str_c("StimN_", unique(data_behav_per_task[[task]]$c_StimN), '_'),
stats = acc_per_memLoad[[task]][[outvar]]
)
# Summary per Ecc:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_") %>%
ungroup() %>%
select(!ppid)
acc_per_ecc[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_ecc[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_ecc[[task]][[outvar]] <- list(
name = "ecc",
printName = "Ecc",
levels = str_c("Ecc_", sort(unique(data_behav_per_task[[task]]$c_Ecc)), '_'),
stats = acc_per_ecc[[task]][[outvar]]
)
print("       **********************************************")
print(str_glue("       ******  Dep. varibale: {outvar}"))
print("       **********************************************")
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
print(str_glue("DV ({if_else(str_detect(tmp$printName, 'overall'), '', 'by ')}{tmp$printName}):\n"))
for (lvl in tmp$levels) {
if (length(tmp$levels) > 1) print(str_glue("{tmp$printName} == {parse_number(lvl)}:"))
print(str_glue("    mean  (%): {tmp$stats[str_c(lvl, 'mean')]}"))
print(str_glue("    SD    (%): {tmp$stats[str_c(lvl, 'sd')]}"))
print(str_glue("    min   (%): {tmp$stats[str_c(lvl, 'min')]}"))
print(str_glue("    max   (%): {tmp$stats[str_c(lvl, 'max')]}"))
print(str_glue("    95% CI(%): {tmp$stats[str_c(lvl, 'ci95lower')]} - {tmp$stats[str_c(lvl, 'ci95upper')]}"))
if (tmp$name != "overall") {
print(str_glue("    95% Cousineau-Morey CI(%): {tmp$stats[str_c(lvl, 'cmci95lower')]} - {tmp$stats[str_c(lvl, 'cmci95upper')]}"))
}
}
cat("\n\n")
}
## Pairwise differences of the mean (with regular CIs):
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_",
id_cols = ppid) %>%
mutate(diff = StimN_2 - StimN_4) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean, sd=sd, ci95lower=ci95lower, ci95upper=ci95upper))
print("Difference between Memory Load conditions:")
print(str_glue("  Mean (CI):     {format(tmp_df$diff_mean, digits=3)} ({format(tmp_df$diff_ci95lower, digits=3)} - {format(tmp_df$diff_ci95upper, digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_mean"), tmp_df$diff_mean, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_cilower"), tmp_df$diff_ci95lower, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_ciupper"), tmp_df$diff_ci95upper, exp_format="%.2f")
cat("\n\n")
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_",
id_cols = ppid) %>%
mutate(diff_Ecc4vsEcc9 = Ecc_4 - Ecc_9,
diff_Ecc4vsEcc14 = Ecc_4 - Ecc_14,
diff_Ecc9vsEcc14 = Ecc_9 - Ecc_14) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean,
sd=sd,
ci95lower=ci95lower,
ci95upper=ci95upper,
t_stat_t= ~ summarize_ttest(x = ., returnval = "t"),
t_stat_p= ~ summarize_ttest(x = ., returnval = "p")))
print("Difference between Eccentricity conditions:")
contrast_pairs <- list(c("4", "9"), c("4", "14"), c("9", "14"))
for (cp in contrast_pairs) {
print(str_glue("  Contrast: {cp[1]} - {cp[2]}"))
print(str_glue(".    Mean (%):     {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], digits=3)}
.    CI (%):       ({format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], digits=3)} - {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_mean"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_cilower"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_ciupper"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_t"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_t')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_p"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_p')]], exp_format="%.3f", is_pval = TRUE)
}
cat("\n\n")
}
}
# VSTM task:
func_analysis_01.1('experiment')
source(file.path(here('Utils', 'load_functions.R')))
# VSTM task:
func_analysis_01.1('experiment')
# VSTM task:
results_anova_behav_dprime_exp <- func_analysis_01.1('experiment')
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
# VSTM task:
results_anova_behav_dprime_exp <- func_analysis_01.1('experiment')
source(file.path(here('Utils', 'load_functions.R')))
# VSTM task:
results_anova_behav_dprime_exp <- func_analysis_01.1('experiment')
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
