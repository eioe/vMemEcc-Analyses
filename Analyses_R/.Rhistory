"maxDecodScoreTime_sensorspace" = 1000,
"maxDecodScoreTime_csp" = 1000,
1
)
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
task_print <- if_else(task == "exp", "vSTM", "perception")
print("#####################################################")
print(str_glue("####  TASK: {task_print}"))
print("#####################################################")
# Summary accuracy overall:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop"
) %>%
ungroup() %>%
select(!ppid)
# Here we cannot calculate Cousineau-Morey CIs, so we take normal CIs:
acc_overall[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
rm(tmp)
stats_overall[[task]][[outvar]] <- list(
name = "overall",
printName = "overall",
levels = c(""),
stats = acc_overall[[task]][[outvar]]
)
# Summary per Memory Load:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_") %>%
ungroup() %>%
select(!ppid)
acc_per_memLoad[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_memLoad[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_memLoad[[task]][[outvar]] <- list(
name = "StimN",
printName = "memLoad",
levels = str_c("StimN_", unique(data_behav_per_task[[task]]$c_StimN), '_'),
stats = acc_per_memLoad[[task]][[outvar]]
)
# Summary per Ecc:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_") %>%
ungroup() %>%
select(!ppid)
acc_per_ecc[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_ecc[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_ecc[[task]][[outvar]] <- list(
name = "ecc",
printName = "Ecc",
levels = str_c("Ecc_", sort(unique(data_behav_per_task[[task]]$c_Ecc)), '_'),
stats = acc_per_ecc[[task]][[outvar]]
)
print("       **********************************************")
print(str_glue("       ******  Dep. varibale: {outvar}"))
print("       **********************************************")
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
print(str_glue("DV ({if_else(str_detect(tmp$printName, 'overall'), '', 'by ')}{tmp$printName}):\n"))
for (lvl in tmp$levels) {
if (length(tmp$levels) > 1) print(str_glue("{tmp$printName} == {parse_number(lvl)}:"))
print(str_glue("    mean  (%): {tmp$stats[str_c(lvl, 'mean')]}"))
print(str_glue("    SD    (%): {tmp$stats[str_c(lvl, 'sd')]}"))
print(str_glue("    min   (%): {tmp$stats[str_c(lvl, 'min')]}"))
print(str_glue("    max   (%): {tmp$stats[str_c(lvl, 'max')]}"))
print(str_glue("    95% CI(%): {tmp$stats[str_c(lvl, 'ci95lower')]} - {tmp$stats[str_c(lvl, 'ci95upper')]}"))
if (tmp$name != "overall") {
print(str_glue("    95% Cousineau-Morey CI(%): {tmp$stats[str_c(lvl, 'cmci95lower')]} - {tmp$stats[str_c(lvl, 'cmci95upper')]}"))
}
}
cat("\n\n")
}
## Pairwise differences of the mean (with regular CIs):
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_",
id_cols = ppid) %>%
mutate(diff = StimN_2 - StimN_4) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean, sd=sd, ci95lower=ci95lower, ci95upper=ci95upper))
print("Difference between Memory Load conditions:")
print(str_glue("  Mean (CI):     {format(tmp_df$diff_mean, digits=3)} ({format(tmp_df$diff_ci95lower, digits=3)} - {format(tmp_df$diff_ci95upper, digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_mean"), tmp_df$diff_mean, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_cilower"), tmp_df$diff_ci95lower, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_ciupper"), tmp_df$diff_ci95upper, exp_format="%.2f")
cat("\n\n")
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_",
id_cols = ppid) %>%
mutate(diff_Ecc4vsEcc9 = Ecc_4 - Ecc_9,
diff_Ecc4vsEcc14 = Ecc_4 - Ecc_14,
diff_Ecc9vsEcc14 = Ecc_9 - Ecc_14) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean,
sd=sd,
ci95lower=ci95lower,
ci95upper=ci95upper,
t_stat_t= ~ summarize_ttest(x = ., returnval = "t"),
t_stat_p= ~ summarize_ttest(x = ., returnval = "p")))
print("Difference between Eccentricity conditions:")
contrast_pairs <- list(c("4", "9"), c("4", "14"), c("9", "14"))
for (cp in contrast_pairs) {
print(str_glue("  Contrast: {cp[1]} - {cp[2]}"))
print(str_glue(".    Mean (%):     {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], digits=3)}
.    CI (%):       ({format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], digits=3)} - {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_mean"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_cilower"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_ciupper"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_t"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_t')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_p"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_p')]], exp_format="%.3f", is_pval = TRUE)
}
cat("\n\n")
}
}
extract_var("n_rej_subs", n_rej_subs, exp_format = "%i")
extract_var("n_tot_trials_prerej_allsubs", 720 * (n_subs_analyzed + n_rej_subs), exp_format = "%i")
extract_var("n_subs_analyzed", n_subs_analyzed, exp_format = "%i")
extract_var("n_tot_trials_prerej", n_tot_trials_prerej, exp_format = "%i")
extract_var("n_trials_rejected", n_tot_trials_prerej - n_tot_trials_postrej, exp_format = "%i")
extract_var("n_tot_trials_postrej", n_tot_trials_postrej, exp_format = "%i")
extract_var("avg_n_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%.2f")
extract_var("min_n_trials_per_sub_postrej", min(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("max_n_trials_per_sub_postrej", max(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("avg_perc_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("min_perc_trials_per_sub_postrej", min(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("max_perc_trials_per_sub_postrej", max(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
for(task in c("exp", "perc")) {
if (task == "exp") {
outvars <- list("c_ResponseCorrect",
"dprime",
"CDA_amp_clustertimes",
"PNP_amp_clustertimes",
"alphapwr_diff_retent",
"maxDecodScore_sensorspace",
"maxDecodScoreTime_sensorspace",
"maxDecodScore_csp",
"maxDecodScoreTime_csp")
} else {
outvars <- list("c_ResponseCorrect")
}
for (outvar in outvars) {
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
for (lvl in tmp$levels) {
for (stat in c("mean", "sd", "min", "max", "ci95lower", "ci95upper", "cmci95lower", "cmci95upper")) {
# for the grand average, we skip the Cousineau-Morey CIs (as we could not calculate them):
if (tmp$name == "overall" && str_detect(stat, "cmci")) {
next
}
extract_var(str_glue("{dv_str}_{task}_{lvl}{stat}"), tmp$stats[str_c(lvl, stat)], exp_format="%.2f")
}
}
}
}
}
# Total number of experimental trials (720 x n):
n_rej_subs <- 3
print(str_glue("N rejected subjects: {n_rej_subs}"))
n_subs_analyzed <- length(unique(data_behav$ppid))
n_tot_trials <- 720 * (n_subs_analyzed + n_rej_subs)
n_tot_trials_prerej <- 720 * n_subs_analyzed
print(str_glue("Total number of recorded experimental trials (720 x {n_subs_analyzed + n_rej_subs}): {n_tot_trials}"))
print(str_glue("Total number of experimental trials after subject rejection (720 x {n_subs_analyzed}): {n_tot_trials_prerej}"))
n_tot_trials_postrej <- data_behav %>% filter(BlockStyle == 'experiment') %>%  drop_na() %>% nrow()
n_trials_rejected <- n_tot_trials_prerej - n_tot_trials_postrej
print(str_glue("Total number of trials after rejection: {n_tot_trials_postrej} ({n_trials_rejected} trials rejected)"))
data_behav_per_task <- vector(mode = "list", length = 2)
data_behav_per_task[['exp']] <- data_behav %>%
filter(BlockStyle == 'experiment') %>%
drop_na() %>%
group_by(ppid, c_StimN, c_Ecc) %>%
mutate(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
ungroup()
data_behav_per_task[['perc']] <- data_behav %>%
filter(BlockStyle == 'perception') %>%
# select(!contains(c('CDA_amp', 'PNP_amp', 'alphapwr_diff_retent'))) %>%
select(ppid, trial_num, block_num, c_StimN, c_Ecc, c_ResponseCorrect, c_ResponseTime, BlockStyle, Hit, FalseAlarm, CorrRej, Miss) %>%
drop_na() %>%
group_by(ppid, c_StimN, c_Ecc) %>%
mutate(dprime = qnorm(mean(c(Hit, 0.5))) - qnorm(mean(c(FalseAlarm, 0.5)))) %>%
ungroup()
# Summary remaining trials:
summary_rem_trials_per_sub <- data_behav_per_task[['exp']] %>%
group_by(ppid) %>%
summarise(n_trials_remaining = n(),
perc_trials_remaining = n_trials_remaining*100 / 720,
.groups = "drop")
print(str_glue("Remaining trials per subject (percentage):
mean: {mean(summary_rem_trials_per_sub$n_trials_remaining)} ({format(mean(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%)
range:  {min(summary_rem_trials_per_sub$n_trials_remaining)} ({format(min(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%) - {max(summary_rem_trials_per_sub$n_trials_remaining)} ({format(max(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%)\n\n"))
acc_overall <- vector(mode = "list", length = 2)
stats_overall <- vector(mode = "list", length = 2)
acc_per_memLoad <- vector(mode = "list", length = 2)
stats_memLoad <- vector(mode = "list", length = 2)
acc_per_ecc <- vector(mode = "list", length = 2)
stats_ecc <- vector(mode = "list", length = 2)
for (task in c('perc', 'exp')) {
if (task == "exp") {
outvars <- list("c_ResponseCorrect",
"dprime",
"CDA_amp_clustertimes",
"PNP_amp_clustertimes",
"alphapwr_diff_retent",
"maxDecodScore_sensorspace",
"maxDecodScoreTime_sensorspace",
"maxDecodScore_csp",
"maxDecodScoreTime_csp")
} else {
outvars <- list("c_ResponseCorrect", "dprime")
}
for (outvar in outvars) {
scaler = switch (outvar,
"c_ResponseCorrect" = 100,
"alphapwr_diff_retent" = 1e12,
"maxDecodScoreTime_sensorspace" = 1000,
"maxDecodScoreTime_csp" = 1000,
1
)
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
task_print <- if_else(task == "exp", "vSTM", "perception")
print("#####################################################")
print(str_glue("####  TASK: {task_print}"))
print("#####################################################")
# Summary accuracy overall:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop"
) %>%
ungroup() %>%
select(!ppid)
# Here we cannot calculate Cousineau-Morey CIs, so we take normal CIs:
acc_overall[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
rm(tmp)
stats_overall[[task]][[outvar]] <- list(
name = "overall",
printName = "overall",
levels = c(""),
stats = acc_overall[[task]][[outvar]]
)
# Summary per Memory Load:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_") %>%
ungroup() %>%
select(!ppid)
acc_per_memLoad[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_memLoad[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_memLoad[[task]][[outvar]] <- list(
name = "StimN",
printName = "memLoad",
levels = str_c("StimN_", unique(data_behav_per_task[[task]]$c_StimN), '_'),
stats = acc_per_memLoad[[task]][[outvar]]
)
# Summary per Ecc:
tmp <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_") %>%
ungroup() %>%
select(!ppid)
acc_per_ecc[[task]][[outvar]] <- tmp %>%
summarise_all(list (mean = mean, sd = sd, min = min, max = max, ci95lower = ci95lower, ci95upper = ci95upper))
# Add Cousineau-Morey CIs:
cmci95 <- cm.ci(tmp, difference = TRUE, conf.level = 0.95)
for (l in colnames(tmp)) {
for (bound in c("lower", "upper")) {
acc_per_ecc[[task]][[outvar]][1, str_c(l, '_cmci95', bound)] <- cmci95[rownames(cmci95)==l, colnames(cmci95)==bound]
}
}
rm(cmci95, tmp)
stats_ecc[[task]][[outvar]] <- list(
name = "ecc",
printName = "Ecc",
levels = str_c("Ecc_", sort(unique(data_behav_per_task[[task]]$c_Ecc)), '_'),
stats = acc_per_ecc[[task]][[outvar]]
)
print("       **********************************************")
print(str_glue("       ******  Dep. varibale: {outvar}"))
print("       **********************************************")
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
print(str_glue("DV ({if_else(str_detect(tmp$printName, 'overall'), '', 'by ')}{tmp$printName}):\n"))
for (lvl in tmp$levels) {
if (length(tmp$levels) > 1) print(str_glue("{tmp$printName} == {parse_number(lvl)}:"))
print(str_glue("    mean  (%): {tmp$stats[str_c(lvl, 'mean')]}"))
print(str_glue("    SD    (%): {tmp$stats[str_c(lvl, 'sd')]}"))
print(str_glue("    min   (%): {tmp$stats[str_c(lvl, 'min')]}"))
print(str_glue("    max   (%): {tmp$stats[str_c(lvl, 'max')]}"))
print(str_glue("    95% CI(%): {tmp$stats[str_c(lvl, 'ci95lower')]} - {tmp$stats[str_c(lvl, 'ci95upper')]}"))
if (tmp$name != "overall") {
print(str_glue("    95% Cousineau-Morey CI(%): {tmp$stats[str_c(lvl, 'cmci95lower')]} - {tmp$stats[str_c(lvl, 'cmci95upper')]}"))
}
}
cat("\n\n")
}
## Pairwise differences of the mean (with regular CIs):
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_StimN) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_StimN,
values_from = perc_resp_corr,
names_prefix = "StimN_",
id_cols = ppid) %>%
mutate(diff = StimN_2 - StimN_4) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean, sd=sd, ci95lower=ci95lower, ci95upper=ci95upper))
print("Difference between Memory Load conditions:")
print(str_glue("  Mean (CI):     {format(tmp_df$diff_mean, digits=3)} ({format(tmp_df$diff_ci95lower, digits=3)} - {format(tmp_df$diff_ci95upper, digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_mean"), tmp_df$diff_mean, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_cilower"), tmp_df$diff_ci95lower, exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_StimN2vsStimN4_ciupper"), tmp_df$diff_ci95upper, exp_format="%.2f")
cat("\n\n")
tmp_df <- data_behav_per_task[[task]] %>%
group_by(ppid, c_Ecc) %>%
summarise(perc_resp_corr = mean(get(outvar)) * scaler,
.groups = "drop") %>%
pivot_wider(names_from = c_Ecc,
values_from = perc_resp_corr,
names_prefix = "Ecc_",
id_cols = ppid) %>%
mutate(diff_Ecc4vsEcc9 = Ecc_4 - Ecc_9,
diff_Ecc4vsEcc14 = Ecc_4 - Ecc_14,
diff_Ecc9vsEcc14 = Ecc_9 - Ecc_14) %>%
ungroup() %>%
select(!ppid) %>%
summarise_all(.funs = c(mean=mean,
sd=sd,
ci95lower=ci95lower,
ci95upper=ci95upper,
t_stat_t= ~ summarize_ttest(x = ., returnval = "t"),
t_stat_p= ~ summarize_ttest(x = ., returnval = "p")))
print("Difference between Eccentricity conditions:")
contrast_pairs <- list(c("4", "9"), c("4", "14"), c("9", "14"))
for (cp in contrast_pairs) {
print(str_glue("  Contrast: {cp[1]} - {cp[2]}"))
print(str_glue(".    Mean (%):     {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], digits=3)}
.    CI (%):       ({format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], digits=3)} - {format(tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], digits=3)})"))
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_mean"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_mean')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_cilower"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95lower')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_ciupper"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_ci95upper')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_t"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_t')]], exp_format="%.2f")
extract_var(str_glue("{dv_str}_{task}_delta_Ecc{cp[1]}vsEcc{cp[2]}_p"), tmp_df[[str_glue('diff_Ecc', cp[1], 'vsEcc', cp[2], '_t_stat_p')]], exp_format="%.3f", is_pval = TRUE)
}
cat("\n\n")
}
}
extract_var("n_rej_subs", n_rej_subs, exp_format = "%i")
extract_var("n_tot_trials_prerej_allsubs", 720 * (n_subs_analyzed + n_rej_subs), exp_format = "%i")
extract_var("n_subs_analyzed", n_subs_analyzed, exp_format = "%i")
extract_var("n_tot_trials_prerej", n_tot_trials_prerej, exp_format = "%i")
extract_var("n_trials_rejected", n_tot_trials_prerej - n_tot_trials_postrej, exp_format = "%i")
extract_var("n_tot_trials_postrej", n_tot_trials_postrej, exp_format = "%i")
extract_var("avg_n_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%.2f")
extract_var("min_n_trials_per_sub_postrej", min(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("max_n_trials_per_sub_postrej", max(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("avg_perc_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("min_perc_trials_per_sub_postrej", min(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("max_perc_trials_per_sub_postrej", max(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
for(task in c("exp", "perc")) {
if (task == "exp") {
outvars <- list("c_ResponseCorrect",
"dprime",
"CDA_amp_clustertimes",
"PNP_amp_clustertimes",
"alphapwr_diff_retent",
"maxDecodScore_sensorspace",
"maxDecodScoreTime_sensorspace",
"maxDecodScore_csp",
"maxDecodScoreTime_csp")
} else {
outvars <- list("c_ResponseCorrect", "dprime")
}
for (outvar in outvars) {
dv_str = switch (outvar,
"c_ResponseCorrect" = "mem_acc",
"dprime" = "dprime",
"alphapwr_diff_retent" = "alphalat",
"CDA_amp_clustertimes" = "cda",
"PNP_amp_clustertimes" = "pnp",
"maxDecodScore_sensorspace" = "decod_sensorspace_maxscore",
"maxDecodScoreTime_sensorspace" = "decod_sensorspace_maxscoretime",
"maxDecodScore_csp" = "decod_csp_maxscore",
"maxDecodScoreTime_csp" = "decod_csp_maxscoretime"
)
for (tmp in list(stats_overall[[task]][[outvar]], stats_memLoad[[task]][[outvar]], stats_ecc[[task]][[outvar]])) {
for (lvl in tmp$levels) {
for (stat in c("mean", "sd", "min", "max", "ci95lower", "ci95upper", "cmci95lower", "cmci95upper")) {
# for the grand average, we skip the Cousineau-Morey CIs (as we could not calculate them):
if (tmp$name == "overall" && str_detect(stat, "cmci")) {
next
}
extract_var(str_glue("{dv_str}_{task}_{lvl}{stat}"), tmp$stats[str_c(lvl, stat)], exp_format="%.2f")
}
}
}
}
}
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
? summarize
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
# VSTM task:
results_anova_behav_dprime_exp <- func_analysis_01.1('experiment')
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
source(file.path(here('Utils', 'load_functions.R')))
# Perception task:
results_anova_behav_dprime_perc <- func_analysis_01.1('perception')
1.627281 - 1.614218
1.491724	- 1.614218
# VSTM task:
results_anova_behav_dprime_exp <- func_analysis_01.1('experiment')
