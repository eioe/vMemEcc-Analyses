---
title: "VME Analysis_R manuscript"
author: "Felix Klotzsche, Sven Ohl"
date: "8 6 2021"
output:
  html_document:
    code_folding: hide

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro
This file prints relevant statistics and plots of the vMemEcc manuscript. Please note, analyses and plots produced in Python are not included here - but in a separate notebook. The most relevant chunkcs of the source code are included in this file as well. For the full code base, please refer to the [repository on GitHub](https://github.com/eioe/vmemecc). 

## Requirements
We ran these analyses using version 4.1.0 (2021-05-18) in RStudio v1.4.1717. 

## Init workspace
Loads packages, custom functions, custom themes, and data. 
Data is made availbale in the workspace as data frame `data_behav`.  

* **ppid** (chr): subject id (e.g., "VME_S09")
* **trial_num** (num): index of the trial in the experiment (includes all trials from all blocks; also training)
    "perception" block: 11-82  
    vSTM block ("experiment"): 93-812  
* **block_num** (num): index of the block 
* **c_StimN** (num): number of memory items (2 or 4)  
* **c_Ecc** (num): stimulus eccentricity (4, 9, 14)  
* **c_ResponseCorrect** (logi): correctness of response in this trial  
* **c_ResponseTime** (num): RT  
* **BlockStyle** (chr): denotes if trial was in "perception" or vSTM ("experiment") block  
* **CDA_amp** (num): avg. CDA amplitude in this trial (see paper for spec. of ROI and time window)
* **PNP_amp** (num): avg. PNP amplitude in this trial (see paper for spec. of ROI and time window)
* **alphapwr_diff_retent** (num): avg. lateralized alpha power in this trial (see paper for spec. of freq. band, ROI and time window)
  

```{r init, message=FALSE, warning=FALSE, echo=TRUE}

#--------------------------------------------------------------------------
# Run main script for analysis for:
#  vMemEcc
#--------------------------------------------------------------------------

library(here)
library(knitr)



#--------------------------------------------------------------------------
# Define pathes
path_global 	    <- here('../..')
path_r_data       <- file.path(path_global, 'Data/DataR')
path_scripts_sven <- file.path(here('Workflow_Sven', 
                                    'osf_experiment1', 
                                    '_RScripts'))
path_extracted_vars <- file.path(path_global, 'Writing', 
                             'Other', 
                             'VME_extracted_vars.json')

#--------------------------------------------------------------------------
## load packages
source(here("Utils", "load_packages.R"))
source(here('Utils', 'print_output.R'))
source(file.path(path_scripts_sven,"loadPackages.R"))

#--------------------------------------------------------------------------

#--------------------------------------------------------------------------
## define colors
source(file.path(path_scripts_sven, "loadColors.R"))
#--------------------------------------------------------------------------

#--------------------------------------------------------------------------
## load function to compute confidence intervals
source(file.path(path_scripts_sven,"loadFunctions.R"))
source(file.path(here('Utils', 'load_functions.R')))
#--------------------------------------------------------------------------

#--------------------------------------------------------------------------
## load theme
source(file.path(path_scripts_sven, "loadTheme.R"))
#--------------------------------------------------------------------------

#--------------------------------------------------------------------------
## load data, assign names for columns and define variable type
source(file.path(here('Utils', 'load_data.R')))
#--------------------------------------------------------------------------


# Write 
extract_var("r_version", "v4.1.0", exp_format = "%s")
extract_var("rstudio_version", "v1.4.1717", exp_format = "%s")

```

## Summary stats: 
**Extract relevants descriptives about the data set.**
```{r, desc stats}
# Total number of experimental trials (720 x n):

n_rej_subs <- 3
print(str_glue("N rejected subjects: {n_rej_subs}"))
n_subs_analyzed <- length(unique(data_behav$ppid))
n_tot_trials <- 720 * (n_subs_analyzed + n_rej_subs)
n_tot_trials_prerej <- 720 * n_subs_analyzed
print(str_glue("Total number of recorded experimental trials (720 x {n_subs_analyzed + n_rej_subs}): {n_tot_trials_prerej}"))
print(str_glue("Total number of experimental trials after subject rejection (720 x {n_subs_analyzed}): {n_tot_trials_prerej}"))
n_tot_trials_postrej <- data_behav %>% filter(BlockStyle == 'experiment') %>%  drop_na() %>% nrow()
print(str_glue("Total number of trials after rejection: {n_tot_trials_postrej}"))

data_behav_per_task <- vector(mode = "list", length = 2)
data_behav_per_task[['exp']] <- data_behav %>% 
  filter(BlockStyle == 'experiment') %>%  
  drop_na() 
data_behav_per_task[['perc']] <- data_behav %>% 
  filter(BlockStyle == 'perception') %>%  
  select(!c(CDA_amp, PNP_amp, alphapwr_diff_retent)) %>% 
  drop_na() 


# Summary remaining trials:
summary_rem_trials_per_sub <- data_behav_per_task[['exp']] %>% 
  group_by(ppid) %>% 
  summarise(n_trials_remaining = n(), 
            perc_trials_remaining = n_trials_remaining*100 / 720, 
            .groups = "drop")



print(str_glue("Remaining trials per subject (percentage):
           mean: {mean(summary_rem_trials_per_sub$n_trials_remaining)} ({format(mean(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%)
           range:  {min(summary_rem_trials_per_sub$n_trials_remaining)} ({format(min(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%) - {max(summary_rem_trials_per_sub$n_trials_remaining)} ({format(max(summary_rem_trials_per_sub$perc_trials_remaining), digits=3)}%)\n\n"))

acc_overall <- vector(mode = "list", length = 2)
stats_overall <- vector(mode = "list", length = 2)
acc_per_memLoad <- vector(mode = "list", length = 2)
stats_memLoad <- vector(mode = "list", length = 2)
acc_per_ecc <- vector(mode = "list", length = 2)
stats_ecc <- vector(mode = "list", length = 2)


for (task in c('exp', 'perc')) {
  
  task_print <- if_else(task == "exp", "vSTM", "perception")
  print("#####################################################")
  print(str_glue("####  TASK: {task_print}"))
  print("#####################################################")
  
  
  # Summary accuracy overall:
  acc_overall[[task]] <- data_behav_per_task[[task]] %>% 
    group_by(ppid) %>% 
    summarise(perc_resp_corr = mean(c_ResponseCorrect) * 100, 
              .groups = "drop"
              ) %>% 
    ungroup() %>% 
    select(!ppid) %>% 
    summarise_all(list (mean = mean, sd = sd, min = min, max = max))
  
  stats_overall[[task]] <- list(
    name = "overall", 
    printName = "overall", 
    levels = c(""),
    stats = acc_overall[[task]]
  )
  
  
  # Summary per Memory Load:
  acc_per_memLoad[[task]] <- data_behav_per_task[[task]] %>% 
    group_by(ppid, c_StimN) %>% 
    summarise(perc_resp_corr = mean(c_ResponseCorrect) * 100, 
              .groups = "drop") %>% 
    pivot_wider(names_from = c_StimN, 
                values_from = perc_resp_corr, 
                names_prefix = "StimN_") %>% 
    ungroup() %>% 
    select(!ppid) %>% 
    summarise_all(list (mean = mean, sd = sd, min = min, max = max))
  
  stats_memLoad[[task]] <- list(
    name = "StimN", 
    printName = "memLoad", 
    levels = str_c("StimN_", unique(data_behav_per_task[[task]]$c_StimN), '_'),
    stats = acc_per_memLoad[[task]]
  )
  
  
  # Summary per Ecc:
  acc_per_ecc[[task]] <- data_behav_per_task[[task]] %>% 
    group_by(ppid, c_Ecc) %>% 
    summarise(perc_resp_corr = mean(c_ResponseCorrect) * 100,
              .groups = "drop") %>% 
    pivot_wider(names_from = c_Ecc, 
                values_from = perc_resp_corr, 
                names_prefix = "Ecc_") %>% 
    ungroup() %>% 
    select(!ppid) %>% 
    summarise_all(list (mean = mean, sd = sd, min = min, max = max))
  
  stats_ecc[[task]] <- list(
    name = "ecc", 
    printName = "Ecc", 
    levels = str_c("Ecc_", sort(unique(data_behav_per_task[[task]]$c_Ecc)), '_'), 
    stats = acc_per_ecc[[task]]
  )

  for (tmp in list(stats_overall[[task]], stats_memLoad[[task]], stats_ecc[[task]])) {
  
    print(str_glue("Memory performance ({if_else(str_detect(tmp$printName, 'overall'), '', 'by ')}{tmp$printName}):\n"))
    for (lvl in tmp$levels) {
      if (length(tmp$levels) > 1) print(str_glue("{tmp$printName} == {parse_number(lvl)}:"))
      print(str_glue("    mean (%): {tmp$stats[str_c(lvl, 'mean')]}"))
      print(str_glue("    SD   (%): {tmp$stats[str_c(lvl, 'sd')]}"))
      print(str_glue("    min  (%): {tmp$stats[str_c(lvl, 'min')]}"))
      print(str_glue("    max  (%): {tmp$stats[str_c(lvl, 'max')]}"))
    }
    cat("\n\n")
  }
}         

extract_var("n_rej_subs", n_rej_subs, exp_format = "%i")
extract_var("n_tot_trials_prerej_allsubs", 720 * (n_subs_analyzed + n_rej_subs), exp_format = "%i")
extract_var("n_subs_analyzed", n_subs_analyzed, exp_format = "%i")
extract_var("n_tot_trials_prerej", n_tot_trials_prerej, exp_format = "%i")
extract_var("n_tot_trials_postrej", n_tot_trials_postrej, exp_format = "%i")
extract_var("n_tot_trials_prerej", n_tot_trials_prerej, exp_format = "%i")
extract_var("avg_n_trials_per_sub_postrej", mean(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%.2f")
extract_var("min_n_trials_per_sub_postrej", min(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("max_n_trials_per_sub_postrej", max(summary_rem_trials_per_sub$n_trials_remaining), exp_format="%i")
extract_var("min_perc_trials_per_sub_postrej", min(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")
extract_var("max_perc_trials_per_sub_postrej", max(summary_rem_trials_per_sub$perc_trials_remaining), exp_format="%.2f")

for(task in c("exp", "perc")) {
  for (tmp in list(stats_overall[[task]], stats_memLoad[[task]], stats_ecc[[task]])) {
    for (lvl in tmp$levels) {
      for (stat in c("mean", "sd", "min", "max")) {
        extract_var(str_glue("mem_acc_{task}_{lvl}{stat}"), tmp$stats[str_c(lvl, stat)], exp_format="%.2f")
      }
    }
  }
}


```


## Analysis 01: 
**Is there an effect of workload or eccentricity on performance in the VSTM task and in the perception task?**

### VSTM Task:
```{r, message=FALSE, warning=FALSE}
# VSTM task:
results_anova_behav_exp <- func_analysis_01('experiment')
```

_show source:_ 
```{r, echo=FALSE}
# Code to chunk:
insert_fun("func_analysis_01")
```
```{r func_analysis_01-source, eval = FALSE}
```

_extract variables:_ 
```{r, echo=FALSE}
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
  eff_print <- eff %>% 
    str_replace_all("c_", "") %>% 
    str_replace_all(":", "-") 
    
  extract_var(str_c("anova_behav_exp_eff_", eff_print, "_F"), summary(results_anova_behav_exp)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
  extract_var(str_c("anova_behav_exp_eff_", eff_print, "_df_within"), summary(results_anova_behav_exp)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]], 
              exp_format = "%i")
  extract_var(str_c("anova_behav_exp_eff_", eff_print, "_df_resid"), summary(results_anova_behav_exp)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]],
              exp_format = "%i")
  extract_var(str_c("anova_behav_exp_eff_", eff_print, "_p"), summary(results_anova_behav_exp)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]], 
              is_pval = TRUE, 
              exp_format = "%.3f")
}
```



### Perception task:
```{r,  message=FALSE, warning=FALSE}
# perceptual Change Detection Task:
results_anova_behav_perc <- func_analysis_01('perception')
```

```{r func_analysis_01-source, eval = FALSE}
```

_extract variables:_ 
```{r, echo=FALSE}
for (eff in c("c_StimN", "c_Ecc", "c_StimN:c_Ecc")) {
  eff_print <- eff %>% 
    str_replace_all("c_", "") %>% 
    str_replace_all(":", "x") 
    
  extract_var(str_c("anova_behav_perc_eff_", eff_print, "_F"), summary(results_anova_behav_perc)[[str_c("Error: ppid:", eff)]][[1]][[eff, "F value"]])
  extract_var(str_c("anova_behav_perc_eff_", eff_print, "_df_within"), summary(results_anova_behav_perc)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Df"]], 
              exp_format = "%i")
  extract_var(str_c("anova_behav_perc_eff_", eff_print, "_df_resid"), summary(results_anova_behav_perc)[[str_c("Error: ppid:", eff)]][[1]][["Residuals", "Df"]], 
              exp_format = "%i")
  extract_var(str_c("anova_behav_perc_eff_", eff_print, "_p"), summary(results_anova_behav_perc)[[str_c("Error: ppid:", eff)]][[1]][[eff, "Pr(>F)"]], 
              is_pval = TRUE, 
              exp_format = "%.3f")
}
```




## Analysis 01 - supplement: 
**Is there an effect of workload or eccentricity on RT in the VSTM task and in the perception task?**  
This analysis was only conducted to exclude that a speed-acc trade-off is taking place. As we did not instruct participants to answer as fast as possible and due to imprecise temporal measurements of RTs with the VR hard- and software, we do not report this analysis in the paper. 

### VSTM Task:
```{r, message=FALSE, warning=FALSE}
# VSTM task:
func_analysis_03('experiment')
```

### Perception Task:
```{r, message=FALSE, warning=FALSE}
# perceptual Change Detection Task:
func_analysis_03('perception')
```


## Analysis 02: 
**Is there an effect of workload or eccentricity on mean CDA amplitude in the VSTM task?**

### CDA amplitude (rmANOVA):
```{r, message=FALSE, warning=FALSE}
func_analysis_05()
```

_show source:_ 
```{r, echo=FALSE}
# Code to chunk:
insert_fun("func_analysis_05")
```
```{r func_analysis_05-source, eval = FALSE}
```


### Analysis 02 - Supplement 1: CDA amplitude (lmer):
A multilevel model confirms the results of the rmANOVA:

```{r, message=FALSE, warning=FALSE}
func_analysis_07('experiment', dep_variable = 'CDA_amp')
```

_show source:_ 
```{r, echo=FALSE}
# Code to chunk:
insert_fun("func_analysis_07")
```
```{r func_analysis_07-source, eval = FALSE}
```

### Analysis 02 - Supplement 2: PNP amplitude (rmANOVA):
Testing the effects of _memory load_ and _eccentricity_ on the mean **PNP amplitude** (see [Papaioannou & Luck, 2020](https://onlinelibrary.wiley.com/doi/abs/10.1111/psyp.13532))

```{r, message=FALSE, warning=FALSE}
func_analysis_09()
```




## Analysis 03: 
**Is there an effect of workload or eccentricity on mean lateralized alpha power in the VSTM task?**
See paper for specifics of parameters re. frequency band, ROI, and time window that were used to calculate mean lateralized power (power **contralaterally - ipsilaterally**)

### lat. alpha power (rmANOVA):
```{r, message=FALSE, warning=FALSE}
func_analysis_06()
```

_show source:_ 
```{r, echo=FALSE}
# Code to chunk:
insert_fun("func_analysis_06")
```
```{r func_analysis_06-source, eval = FALSE}
```

### Analysis 03 - Supplement 1: lat. alpha power (lmer):
A multilevel model confirms the results of the rmANOVA:

```{r, message=FALSE, warning=FALSE}
func_analysis_10('experiment', dep_variable = 'alpha_pwr')
```



```