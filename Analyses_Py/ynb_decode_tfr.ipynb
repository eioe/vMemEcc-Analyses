{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test, f_mway_rm, f_threshold_mway_rm\n",
    "from mne.decoding import CSP\n",
    "from library import helpers, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epos(subID, part_epo, signaltype, condition, event_dict, picks=None):\n",
    "    \"\"\"Load a set of specified epochs.\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    subID : str\n",
    "        Subject identifier (eg, 'VME_S05')\n",
    "    part_epo : str\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon'\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "    condition: str\n",
    "        Experimental condition. Combination of 'Ecc' and 'Load' (eg, 'LoadLow' or 'LoadLowEccS')\n",
    "    event_dict: dict\n",
    "        Dictionnary explaining the event codes. Normally this can be grabbed from config.event_dict\n",
    "    picks: list\n",
    "        list of channel names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mne.Epochs\n",
    "        Array of selected epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    if signaltype == 'uncollapsed':\n",
    "        fname = op.join(config.path_rejepo, subID + '-' + part_epo +\n",
    "                        '-postica-rejepo' + '-epo.fif')\n",
    "    elif signaltype in ['collapsed']:\n",
    "        fname = op.join(config.path_epos_sorted, part_epo, signaltype,\n",
    "                        subID + '-epo.fif')\n",
    "    else:\n",
    "        raise ValueError(f'Invalid value for \"signaltype\": {signaltype}')\n",
    "    epos = mne.read_epochs(fname, verbose=False)\n",
    "    epos = epos.pick_types(eeg=True)\n",
    "    \n",
    "    uppers = [letter.isupper() for letter in condition]\n",
    "    if (np.sum(uppers) > 2):\n",
    "        cond_1 = condition[:np.where(uppers)[0][2]]\n",
    "        cond_2 = condition[np.where(uppers)[0][2]:]\n",
    "        selection = epos[event_dict[cond_1]][event_dict[cond_2]]\n",
    "    else:\n",
    "        selection = epos[event_dict[condition]]\n",
    "    return(selection)\n",
    "\n",
    "\n",
    "def get_sensordata(subID, part_epo, signaltype, conditions, event_dict, picks=None):\n",
    "    \"\"\"Load a set of specified epochs for classification.\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    subID : str\n",
    "        Subject identifier (eg, 'VME_S05')\n",
    "    part_epo : str\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon'\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "    conditions: list\n",
    "        List of experimental conditions. Combination of 'Ecc' and 'Load' (eg, 'LoadLow' or 'LoadLowEccS')\n",
    "    event_dict: dict\n",
    "        Dictionnary explaining the event codes. Normally this can be grabbed from config.event_dict\n",
    "    picks: list\n",
    "        list of channel names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_epos: Epochs\n",
    "        Array of selected epochs, sorted by class (starting with class '0').\n",
    "    y: list\n",
    "        Sorted list of labels.\n",
    "    times_n: array, 1d\n",
    "        Times of the samples within the single epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    epos_dict = defaultdict(dict)\n",
    "    for cond in conditions:\n",
    "        epos_dict[cond] = get_epos(subID,\n",
    "                                   part_epo=part_epo,\n",
    "                                   signaltype=signaltype,\n",
    "                                   condition=cond,\n",
    "                                   event_dict=event_dict, \n",
    "                                   picks=picks)\n",
    "\n",
    "    times = epos_dict[conditions[0]][0].copy().times\n",
    "\n",
    "    # Setup data:\n",
    "    X_epos = mne.concatenate_epochs([epos_dict[cond] for cond in conditions])\n",
    "    n_ = {cond: len(epos_dict[cond]) for cond in conditions}\n",
    "\n",
    "    times_n = times\n",
    "\n",
    "    y = np.r_[np.zeros(n_[conditions[0]]),\n",
    "              np.concatenate([(np.ones(n_[conditions[i]]) * i)\n",
    "                              for i in np.arange(1, len(conditions))])]\n",
    "\n",
    "    return X_epos, y, times_n\n",
    "\n",
    "\n",
    "def decode(sub_list_str, conditions, event_dict, reps=1, shuffle_labels=False, save_scores=True, save_csp_patterns=True, \n",
    "           overwrite = False, part_epo = 'stimon', signaltype='collapsed', picks=None):\n",
    "    \"\"\"Apply CSP and LDA to perform binary classification from (the power) of epoched data.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Original code from: \n",
    "    https://mne.tools/stable/auto_examples/decoding/plot_decoding_csp_timefreq.html#\n",
    "    sphx-glr-auto-examples-decoding-plot-decoding-csp-timefreq-py\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_list_str : list of str\n",
    "        List of subject identifiers (eg, 'VME_S05')\n",
    "    conditions: list\n",
    "        List of experimental conditions that shall be compared/decoded. \n",
    "        Combination of 'Ecc' and 'Load' (eg, 'LoadLow' or 'LoadLowEccS')\n",
    "    event_dict: dict\n",
    "        Dictionnary explaining the event codes. Normally this can be grabbed from config.event_dict\n",
    "    reps: int \n",
    "        Number of repetions for the CV procedure.\n",
    "    shuffle_labels: bool\n",
    "        Shuffle the labels to produce a null distribution.\n",
    "    save_scores: bool, optional\n",
    "        Shall the decoding scores be written to disk? (default is True).\n",
    "    save_patterns: bool, optional\n",
    "        Shall the CSP patterns be written to disk? (default is True).\n",
    "    overwrite : bool\n",
    "        Overwrite existing folders (True) or append current datetime to foldername (False). (default is False)\n",
    "    part_epo : str, optional\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon' (default is 'stimon').\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "                                                       (default is 'collapsed'.)\n",
    "    picks: list\n",
    "        list of channel names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf_scores_list: list\n",
    "        list of 2d arrays (freq x time) with the decoding scores per subject\n",
    "    centered_w_times: list\n",
    "        list with the times around which the decoding windows were centered.\n",
    "    \"\"\"\n",
    "    \n",
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    scoring = 'accuracy'\n",
    "    cv_folds = 5\n",
    "    n_components = 6\n",
    "    \n",
    "    csp = CSP(n_components=n_components, reg=None, log=True, norm_trace=False)\n",
    "    clf = make_pipeline(csp, LinearDiscriminantAnalysis())\n",
    "    \n",
    "    # Classification & time-frequency parameters\n",
    "    tmin = -0.5 # -config.times_dict['cue_dur']\n",
    "    tmax =  2.5  # config.times_dict['stim_dur'] + config.times_dict['retention_dur']\n",
    "    n_cycles = None  # how many complete cycles: used to define window size\n",
    "    w_size = 0.5\n",
    "    w_overlap = 0.5 # how much shall the windows overlap [value in [0,1]; 0: no overlap, 1: full overlap]\n",
    "    min_freq = 6\n",
    "    max_freq = 26\n",
    "    n_freqs = 10  # how many frequency bins to use\n",
    "\n",
    "    # Get datetime identifier for uniqure folder names (if not overwriting):\n",
    "    datetime_str = datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "\n",
    "    # Assemble list of frequency range tuples\n",
    "    freqs = np.linspace(min_freq, max_freq, n_freqs + 1)  # assemble frequencies\n",
    "    freq_ranges = list(zip(freqs[:-1], freqs[1:]))  # make freqs list of tuples# Setup list of seeds for the repetitions:\n",
    "    \n",
    "    # Setup list of seeds for the repetitions:\n",
    "    np.random.seed(seed=42)\n",
    "    rep_seeds = np.random.choice(range(10 * reps), reps)\n",
    "    \n",
    "\n",
    "    if ((n_cycles is not None) and (w_size is None)): \n",
    "        # Infer window spacing from the max freq and number of cycles to avoid gaps\n",
    "        window_spacing = (n_cycles / np.max(freqs) / 2.)\n",
    "        centered_w_times = np.arange(tmin, tmax, window_spacing)[1:]\n",
    "    elif (((w_size is not None)) and (n_cycles is None)): \n",
    "        assert 0 <= float(w_overlap or -1) < 1, f'Invalid value for w_overlap: {w_overlap}'\n",
    "        step_size = w_size * (1 - w_overlap)\n",
    "        centered_w_times = np.arange(tmin + (w_size / 2.), tmax - (w_size / 2) + 0.001, step_size)\n",
    "    else: \n",
    "        raise ValueError(f'Invalid combination of values for w_size and n_cylces. Exactly one must be None.')\n",
    "\n",
    "    n_windows = len(centered_w_times)\n",
    "\n",
    "    tf_scores_list = list()\n",
    "    tf_patterns_list = list()\n",
    "    completed_subs = list()\n",
    "    for subID in sub_list_str:\n",
    "        part_epo = part_epo\n",
    "\n",
    "        print(f'Running {subID}')\n",
    "\n",
    "        X_epos, y, t = get_sensordata(subID, part_epo, signaltype, conditions, event_dict, picks)\n",
    "        n_channels = len(X_epos.ch_names)\n",
    "        # init scores\n",
    "        tf_scores = np.zeros((n_freqs, n_windows))\n",
    "        tf_scores_tmp = np.zeros((reps, n_freqs, n_windows))\n",
    "        tf_patterns = np.zeros((n_components, n_channels, n_freqs, n_windows))\n",
    "\n",
    "        # Loop through each frequency range of interest\n",
    "        for freq, (fmin, fmax) in enumerate(freq_ranges):\n",
    "\n",
    "            # print(f'Freq. {freq} of {len(freq_ranges)}')\n",
    "\n",
    "            if (w_size is None):\n",
    "                # Infer window size based on the frequency being used (default behavuior is to use a fixed w_size)\n",
    "                w_size = n_cycles / ((fmax + fmin) / 2.)  # in seconds\n",
    "\n",
    "            # Apply band-pass filter to isolate the specified frequencies\n",
    "            X_epos_filter = X_epos.copy().filter(fmin, fmax, n_jobs=-2, fir_design='firwin')\n",
    "\n",
    "            # Roll covariance, csp and lda over time\n",
    "            for t, w_time in enumerate(centered_w_times):\n",
    "\n",
    "                # Center the min and max of the window\n",
    "                w_tmin = w_time - w_size / 2.\n",
    "                w_tmax = w_time + w_size / 2.\n",
    "\n",
    "                # Crop data into time-window of interest\n",
    "                X = X_epos_filter.copy().crop(w_tmin, w_tmax).get_data()\n",
    "                \n",
    "                # Run repeated CV to estimate decoding score:\n",
    "                for rep, rand_state in enumerate(rep_seeds):\n",
    "                    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=rand_state)\n",
    "\n",
    "                    if shuffle_labels:\n",
    "                        np.random.seed(rand_state)\n",
    "                        np.random.shuffle(y)\n",
    "                    # Save mean scores over folds for each frequency and time window for this repetition\n",
    "                    tf_scores_tmp[rep, freq, t] = np.mean(cross_val_score(estimator=clf, X=X, y=y,\n",
    "                                                                          scoring='accuracy', cv=cv,\n",
    "                                                                          n_jobs=-2), axis=0)\n",
    "                if save_csp_patterns:\n",
    "                    # get CSP patterns - fitted to all data:\n",
    "                    csp.fit(X, y)\n",
    "                    patterns_ = getattr(csp, 'patterns_')\n",
    "                    tf_patterns[:, :, freq, t] = patterns_[:n_components, :]\n",
    "                \n",
    "        tf_scores = np.mean(tf_scores_tmp, axis=0)        \n",
    "        tf_scores_list.append(tf_scores)\n",
    "        tf_patterns_list.append(tf_patterns)\n",
    "\n",
    "        # save info:\n",
    "        if (save_scores or save_csp_patterns):\n",
    "            completed_subs.append(subID)\n",
    "            info_dict = {'subs': completed_subs,\n",
    "                         'tmin': tmin, \n",
    "                         'tmax': tmax, \n",
    "                         'n_cycles': n_cycles, \n",
    "                         'w_size': w_size,\n",
    "                         'w_overlap': w_overlap,\n",
    "                         'min_freq': min_freq, \n",
    "                         'max_freq': max_freq,\n",
    "                         'n_freqs': n_freqs,\n",
    "                         'cv_folds': cv_folds, \n",
    "                         'reps': reps,\n",
    "                         'scoring': scoring}\n",
    "            \n",
    "            if shuffle_labels:\n",
    "                shuf_labs = 'labels_shuffled'\n",
    "            else: \n",
    "                shuf_labs = ''\n",
    "            \n",
    "            fpath = op.join(config.path_decod_tfr, part_epo, signaltype, contrast_str, shuf_labs)\n",
    "            if (op.exists(fpath) and not overwrite):\n",
    "                path_save = op.join(config.path_decod_tfr, part_epo, signaltype, contrast_str + datetime_str, shuf_labs)\n",
    "            else:\n",
    "                path_save = fpath\n",
    "            helpers.chkmk_dir(path_save)\n",
    "            fname = op.join(path_save, 'info.json')\n",
    "            with open(fname, 'w+') as outfile:  \n",
    "                json.dump(info_dict, outfile)\n",
    "        \n",
    "        if save_csp_patterns:\n",
    "            sub_patterns_ = np.asarray(tf_patterns_list)\n",
    "            fpath = op.join(path_save, 'patterns')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'patterns_per_sub.npy')\n",
    "            np.save(fname, sub_patterns_)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', centered_w_times)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freq_ranges)\n",
    "            del(fpath, fname)\n",
    "        \n",
    "        \n",
    "        if save_scores:\n",
    "            sub_scores_ = np.asarray(tf_scores_list)\n",
    "            fpath = op.join(path_save, 'scores')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "            np.save(fname, sub_scores_)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', centered_w_times)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freq_ranges)\n",
    "            del(fpath, fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return tf_scores_list, centered_w_times\n",
    "\n",
    "\n",
    "def load_scores_decod_tfr(conditions, part_epo='stimon', signaltype='collapsed'):\n",
    "    \"\"\"Load decoding results from disc.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conditions : list\n",
    "        List of strings containing the classes of the classification. \n",
    "    part_epo : str, optional\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon' (default is 'stimon').\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "                                                       (default is 'collapsed'.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results: ndarray \n",
    "        Array with decoding results (subjects x freqs x times)\n",
    "    times: array, 1d\n",
    "    freqs: array, 1d\n",
    "    \"\"\"\n",
    "    \n",
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    fpath = op.join(config.path_decod_tfr, part_epo, signaltype, contrast_str, 'scores')\n",
    "    fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "    res = np.load(fname)\n",
    "    times = np.load(fname[:-4] + '__times.npy')\n",
    "    freqs = np.load(fname[:-4] + '__freqs.npy')\n",
    "    return(res, times, freqs)\n",
    "\n",
    "\n",
    "def plot_decod_image_tfr(scores, conditions, times, freqs, ax=None):\n",
    "    \"\"\"Plot a heatmap with decoding accuracy over time and frequency. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores : ndarray, 2d\n",
    "        2d array with decoding results (freqs x timepoints)\n",
    "    conditions : list\n",
    "        List of strings containing the classes of the classification. \n",
    "    times: array, 1d\n",
    "        Timepoints\n",
    "    freqs: array, 1d\n",
    "        Frequencies \n",
    "    ax: axis, optional\n",
    "        Axis to plot into.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image\n",
    "        AxisImage\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    dx = np.diff(times)[0] / 2\n",
    "    dy = 0 #np.diff(freqs)[0] / 2\n",
    "    extent = [times.min()-dx, times.max()+dx,\n",
    "              freqs.min()-dy, freqs.max()+dy]             \n",
    "    image = ax.imshow(scores, origin='lower', cmap='Greens', aspect='auto', extent=extent)\n",
    "    ax.set_yticks([f for frange in freqs for f in frange])\n",
    "    ax.set_ylabel('frequency (Hz)')\n",
    "    return(image)\n",
    "\n",
    "\n",
    "def plot_score_ts(scores_df, plt_dict, color, ax=None, n_boot=1000):\n",
    "    \"\"\"Plot the decoding scores as timeseries line plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores_df : DataFrame \n",
    "        Data frame containing accuracies per time point in epoch. Long format. \n",
    "        Needed columns: 'time',\n",
    "                        'score'\n",
    "    plt_dict: dict\n",
    "        Dict containing info relevant for plotting. \n",
    "        Entries needed: 't_stimon': relative time of stimulus onset\n",
    "                        'xmin': minimal time to be plotted\n",
    "                        'xmax': maximal time to be plotted\n",
    "    color: str\n",
    "        A single color string referred to by name, RGB or RGBA code,\n",
    "        for instance ‘red’ or ‘#a98d19’.    \n",
    "    ax: axis, optional\n",
    "        Axis to plot into.\n",
    "    n_boot: int\n",
    "        Number of bootstrapping iterations for the CI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image\n",
    "        AxisImage\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    image = sns.lineplot(x='time', \n",
    "                 y='score', \n",
    "                 color = color,\n",
    "                 data=scores_df, \n",
    "                 n_boot=n_boot,  \n",
    "                 ax=ax)\n",
    "    ytick_range = ax.get_ylim()\n",
    "    ax.set(xlim=(plt_dict['xmin'], plt_dict['xmax']), ylim=ytick_range)\n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.axvspan(plt_dict['t_stimon'], plt_dict['t_stimon']+0.2, color='grey', alpha=0.3)\n",
    "    ax.axvspan(plt_dict['t_stimon']+ 2.2, plt_dict['t_stimon'] + 2.5, color='grey', alpha=0.3)\n",
    "    ax.vlines((plt_dict['t_stimon'], plt_dict['t_stimon']+0.2, plt_dict['t_stimon']+2.2),\n",
    "              ymin=ytick_range[0], ymax=ytick_range[1], \n",
    "              linestyles='dashed')\n",
    "    ax.hlines(0.5, xmin=plt_dict['xmin'], xmax=plt_dict['xmax'])\n",
    "    return(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-d3bdeeed5e66>:35: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epos = mne.read_epochs(fname, verbose=False)\n",
      "<ipython-input-76-d3bdeeed5e66>:35: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epos = mne.read_epochs(fname, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "da = get_epos('VME_S01', 'stimon', 'collapsed', 'LoadLow', config.event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fp1',\n",
       " 'Fz',\n",
       " 'F3',\n",
       " 'F7',\n",
       " 'FC5',\n",
       " 'FC1',\n",
       " 'C3',\n",
       " 'T7',\n",
       " 'TP9',\n",
       " 'CP5',\n",
       " 'CP1',\n",
       " 'Pz',\n",
       " 'P3',\n",
       " 'P7',\n",
       " 'O1',\n",
       " 'Oz',\n",
       " 'O2',\n",
       " 'P4',\n",
       " 'P8',\n",
       " 'TP10',\n",
       " 'CP6',\n",
       " 'CP2',\n",
       " 'Cz',\n",
       " 'C4',\n",
       " 'T8',\n",
       " 'FC6',\n",
       " 'FC2',\n",
       " 'F4',\n",
       " 'F8',\n",
       " 'Fp2',\n",
       " 'AF3',\n",
       " 'AFz',\n",
       " 'F1',\n",
       " 'F5',\n",
       " 'FT7',\n",
       " 'FC3',\n",
       " 'C1',\n",
       " 'C5',\n",
       " 'TP7',\n",
       " 'CP3',\n",
       " 'P1',\n",
       " 'P5',\n",
       " 'PO7',\n",
       " 'PO3',\n",
       " 'POz',\n",
       " 'PO4',\n",
       " 'PO8',\n",
       " 'P6',\n",
       " 'P2',\n",
       " 'CPz',\n",
       " 'CP4',\n",
       " 'TP8',\n",
       " 'C6',\n",
       " 'C2',\n",
       " 'FC4',\n",
       " 'FT8',\n",
       " 'F6',\n",
       " 'AF4',\n",
       " 'F2',\n",
       " 'Iz']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = op.join(config.path_decod_tfr, 'stimon', 'collapsed', 'LoadLow_vs_LoadHigh', 'roc_auc', 'shrinkage0.4', 'Right', '', 'VME_S03', 'scores')\n",
    "fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "sc = np.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.51301136, 0.54055361, 0.49818109, 0.46754298, 0.5263243 ,\n",
       "          0.48362617, 0.51670819, 0.51228074, 0.50270979, 0.53165501,\n",
       "          0.50563811]],\n",
       "\n",
       "        [[0.4952921 , 0.50886728, 0.50830565, 0.45323718, 0.52288024,\n",
       "          0.50944274, 0.51874272, 0.54024767, 0.50274038, 0.48805143,\n",
       "          0.49426282]],\n",
       "\n",
       "        [[0.4834579 , 0.52798951, 0.50147145, 0.44613782, 0.51822844,\n",
       "          0.50348485, 0.49721154, 0.47800991, 0.48487981, 0.503412  ,\n",
       "          0.49250364]],\n",
       "\n",
       "        [[0.50368663, 0.51990312, 0.49818109, 0.48042468, 0.5475051 ,\n",
       "          0.49700685, 0.51260854, 0.51575612, 0.4885169 , 0.49270032,\n",
       "          0.48728365]],\n",
       "\n",
       "        [[0.51676064, 0.52698864, 0.50117788, 0.48498834, 0.52503351,\n",
       "          0.52128424, 0.53570513, 0.53153409, 0.51299971, 0.50937063,\n",
       "          0.49855842]],\n",
       "\n",
       "        [[0.47286276, 0.52809659, 0.48427156, 0.45586976, 0.50783144,\n",
       "          0.50949082, 0.48999053, 0.49950466, 0.4786808 , 0.51819857,\n",
       "          0.47649767]],\n",
       "\n",
       "        [[0.50358173, 0.52522946, 0.49590399, 0.48440268, 0.48904866,\n",
       "          0.55643648, 0.51168488, 0.48407197, 0.45162369, 0.4898259 ,\n",
       "          0.48824228]],\n",
       "\n",
       "        [[0.51377404, 0.51001311, 0.49184659, 0.44083916, 0.50608683,\n",
       "          0.52429123, 0.5396336 , 0.51850233, 0.49458406, 0.55071897,\n",
       "          0.50669872]],\n",
       "\n",
       "        [[0.51301136, 0.54055361, 0.49818109, 0.46754298, 0.5263243 ,\n",
       "          0.48362617, 0.51670819, 0.51228074, 0.50270979, 0.53165501,\n",
       "          0.50563811]],\n",
       "\n",
       "        [[0.47767628, 0.50913534, 0.46220134, 0.46601399, 0.50874344,\n",
       "          0.52595862, 0.52716565, 0.50973266, 0.47338068, 0.50344187,\n",
       "          0.49225087]],\n",
       "\n",
       "        [[0.49448572, 0.49599578, 0.48169143, 0.46176719, 0.51571168,\n",
       "          0.52832532, 0.481309  , 0.479088  , 0.51110868, 0.52715982,\n",
       "          0.48683057]],\n",
       "\n",
       "        [[0.5051384 , 0.52509834, 0.48972319, 0.47149403, 0.52833989,\n",
       "          0.5379123 , 0.52744464, 0.52662442, 0.45732226, 0.51742643,\n",
       "          0.47532197]],\n",
       "\n",
       "        [[0.49974869, 0.50130609, 0.48668196, 0.4766674 , 0.49736961,\n",
       "          0.50916448, 0.51216492, 0.48070804, 0.518066  , 0.54012092,\n",
       "          0.48215909]],\n",
       "\n",
       "        [[0.52466783, 0.5186604 , 0.50699956, 0.49549388, 0.52489948,\n",
       "          0.50231133, 0.5186961 , 0.50665137, 0.52103147, 0.52587267,\n",
       "          0.50724359]],\n",
       "\n",
       "        [[0.49677957, 0.5369544 , 0.50671037, 0.46004808, 0.50983683,\n",
       "          0.50039263, 0.5204021 , 0.50267483, 0.50065122, 0.54477564,\n",
       "          0.48122305]],\n",
       "\n",
       "        [[0.48785912, 0.53022072, 0.52230551, 0.45783217, 0.49669435,\n",
       "          0.52737325, 0.49377768, 0.49537223, 0.50676573, 0.52181964,\n",
       "          0.50543779]],\n",
       "\n",
       "        [[0.47311699, 0.52581804, 0.49560315, 0.46239365, 0.48392264,\n",
       "          0.51419653, 0.50118808, 0.49142701, 0.49340618, 0.53694784,\n",
       "          0.50512966]],\n",
       "\n",
       "        [[0.49068692, 0.54325612, 0.53720353, 0.46546547, 0.5167752 ,\n",
       "          0.53942672, 0.50645688, 0.52855186, 0.51339598, 0.53477127,\n",
       "          0.50114656]],\n",
       "\n",
       "        [[0.45951267, 0.54184441, 0.5226333 , 0.47360213, 0.52016973,\n",
       "          0.54007576, 0.5051435 , 0.49606498, 0.51410329, 0.52481061,\n",
       "          0.51885198]],\n",
       "\n",
       "        [[0.49026661, 0.56163899, 0.5163396 , 0.44493954, 0.49277972,\n",
       "          0.50875291, 0.53447407, 0.52993881, 0.5139292 , 0.51584717,\n",
       "          0.50290793]]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "old_log_level = mne.set_log_level('WARNING', return_old_level=True)\n",
    "print(old_log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = np.setdiff1d(np.arange(1, 2), config.ids_missing_subjects +\n",
    "                        config.ids_excluded_subjects)               \n",
    "sub_list_str = ['VME_S%02d' % sub for sub in sub_list]\n",
    "\n",
    "cond_dict = {'Load': ['LoadLow', 'LoadHigh'], \n",
    "             'Ecc': ['EccS', 'EccM', 'EccL']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running VME_S01\n",
      "creating dir: /draco/ptmp/fklotzsche/Experiments/vMemEcc/Data/DataMNE/EEG/10_tfr_decoding/stimon/collapsed/LoadLow_vs_LoadHigh/labels_shuffled\n",
      "creating dir: /draco/ptmp/fklotzsche/Experiments/vMemEcc/Data/DataMNE/EEG/10_tfr_decoding/stimon/collapsed/LoadLow_vs_LoadHigh/labels_shuffled/patterns\n",
      "creating dir: /draco/ptmp/fklotzsche/Experiments/vMemEcc/Data/DataMNE/EEG/10_tfr_decoding/stimon/collapsed/LoadLow_vs_LoadHigh/labels_shuffled/scores\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "res_load = decode(sub_list_str[:1], ['LoadLow', 'LoadHigh'], config.event_dict, reps=5, shuffle_labels=True,\n",
    "                  overwrite=True, picks='all')\n",
    "#res_ecc_sl = decode(sub_list_str, ['EccS', 'EccL'], config.event_dict, reps=5, overwrite=True)\n",
    "#res_ecc_ml = decode(sub_list_str, ['EccM', 'EccL'], config.event_dict, reps=5, overwrite=True)\n",
    "#res_ecc_sm = decode(sub_list_str, ['EccS', 'EccM'], config.event_dict, reps=5, overwrite=True)\n",
    "# res_load_eccL = decode(sub_list_str, ['LoadLowEccL', 'LoadHighEccL'], config.event_dict, reps=5, overwrite=True)\n",
    "# res_load_eccS = decode(sub_list_str, ['LoadLowEccS', 'LoadHighEccS'], config.event_dict, reps=5, overwrite=True)\n",
    "# res_load_eccM = decode(sub_list_str, ['LoadLowEccM', 'LoadHighEccM'], config.event_dict, reps=5, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running VME_S01\n",
      "Running VME_S02\n",
      "Running VME_S03\n",
      "Running VME_S04\n",
      "Running VME_S05\n",
      "Running VME_S06\n",
      "Running VME_S08\n",
      "Running VME_S09\n",
      "Running VME_S10\n",
      "Running VME_S13\n",
      "Running VME_S15\n",
      "Running VME_S16\n",
      "Running VME_S17\n",
      "Running VME_S18\n",
      "Running VME_S20\n",
      "Running VME_S21\n",
      "Running VME_S23\n",
      "Running VME_S24\n",
      "Running VME_S25\n",
      "Running VME_S26\n",
      "Running VME_S27\n"
     ]
    }
   ],
   "source": [
    "res_load = decode(sub_list_str, ['LoadLow', 'LoadHigh'], config.event_dict, reps=5, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
