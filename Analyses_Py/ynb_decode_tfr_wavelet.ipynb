{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import mne\n",
    "from mne.decoding import (SlidingEstimator,  # GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from library import helpers, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_singletrialtfr(subID, condition, pwr_style='induced', \n",
    "                        part_epo='fulllength', baseline=None, mode=None): \n",
    "    fpath = op.join(config.path_tfrs, pwr_style, 'tfr_lists', part_epo)\n",
    "    fname = op.join(fpath, subID + '-collapsed-singletrialTFRs-tfr.h5')\n",
    "    tfr_ = mne.time_frequency.read_tfrs(fname)\n",
    "    for idx in range(len(tfr_)):\n",
    "        if tfr_[idx].comment == condition:\n",
    "            tfr_selection = tfr_[idx]\n",
    "    \n",
    "    if baseline is not None:\n",
    "        tfr_selection.apply_baseline(baseline=baseline, mode=mode)\n",
    "    \n",
    "    return tfr_selection\n",
    "\n",
    "\n",
    "def batch_trials(epos, batch_size):\n",
    "    n_trials = len(epos)\n",
    "    n_batches = int(n_trials / batch_size)\n",
    "    rnd_seq = np.arange(n_trials)\n",
    "    np.random.shuffle(rnd_seq)\n",
    "    rnd_seq = rnd_seq[:n_batches * batch_size]\n",
    "    rnd_seq = rnd_seq.reshape(-1, batch_size)\n",
    "    batches = [epos[b].average() for b in rnd_seq]\n",
    "    return(batches)\n",
    "\n",
    "\n",
    "\n",
    "def avg_time(data, step=25, times=None):\n",
    "    orig_shape = data.shape\n",
    "    n_fill = step - (orig_shape[-1] % step)\n",
    "    fill_shape = np.asarray(orig_shape)\n",
    "    fill_shape[-1] = n_fill\n",
    "    fill = np.ones(fill_shape) * np.nan\n",
    "    data_f = np.concatenate([data, fill], axis=-1)\n",
    "    data_res = np.nanmean(data_f.reshape(*orig_shape[:-1], -1, step), axis=-1)\n",
    "\n",
    "    if times is not None:\n",
    "        f_times = np.r_[times, [np.nan] * n_fill]\n",
    "        n_times = np.nanmean(f_times.reshape(-1, step), axis=-1)\n",
    "        return data_res, n_times\n",
    "    else:\n",
    "        return data_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_epo='fulllength' \n",
    "signaltype='collapsed'\n",
    "freqs_decod=[10]\n",
    "event_dict=config.event_dict, \n",
    "n_rep_sub=1\n",
    "shuffle_labels=False\n",
    "batch_size=10\n",
    "smooth_winsize=10\n",
    "save_single_rep_scores=False\n",
    "save_scores=True \n",
    "save_patterns=True\n",
    "overwrite=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    scoring = 'accuracy'\n",
    "    cv_folds = 5\n",
    "\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        LinearModel(LogisticRegression(solver='liblinear',\n",
    "                                                       penalty='l2',\n",
    "                                                       random_state=42,\n",
    "                                                       verbose=False)))\n",
    "\n",
    "    se = SlidingEstimator(clf,\n",
    "                          scoring=scoring,\n",
    "                          n_jobs=-2,\n",
    "                          verbose=0)\n",
    "\n",
    "    sub_scores = list()\n",
    "    sub_scores_per_rep = list()\n",
    "    sub_coef = list()\n",
    "    times_n = list()\n",
    "\n",
    "    for sub in sub_list_str:\n",
    "        print(f'### RUNING SUBJECT {sub}')\n",
    "        all_scores = list()\n",
    "        all_coef = list()\n",
    "        for i in np.arange(n_rep_sub):\n",
    "            X_allfreqs, y, times_n, freqs = get_data(sub,\n",
    "                                                    part_epo=part_epo,\n",
    "                                                    signaltype=signaltype,\n",
    "                                                    conditions=conditions,\n",
    "                                                    event_dict=event_dict,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    smooth_winsize=smooth_winsize)\n",
    "            if freqs_decod == 'all':\n",
    "                freqs_select = freqs\n",
    "            else:\n",
    "                freqs_select = [f for f in freqs_decod if f in freqs]\n",
    "                if len(freqs_select) < len(freqs_decod):\n",
    "                    f_not_found = [f for f in freqs_decod if f not in freqs]\n",
    "                    ending = 'y' if (len(f_not_found) == 1) else 'ies'\n",
    "                    raise ValueError(f'Frequenc{ending} not present in data: {f_not_found}')\n",
    "            if shuffle_labels:\n",
    "                np.random.shuffle(y)\n",
    "            for i in np.unique(y):\n",
    "                print(f'Size of class {i}: {np.sum(y == i)}\\n')\n",
    "            \n",
    "            scores_per_freq = np.zeros((len(freqs_select), len(times_n)))\n",
    "            coefs_per_freq = np.zeros((len(freqs_select), *X_allfreqs.shape[-2:]))\n",
    "            for idx, freq in enumerate(freqs_select):\n",
    "                 print(f'#### Frequency {idx+1} from {len(freqs_select)}')\n",
    "                 freq_idx = list(freqs).index(freq)\n",
    "                 X = X_allfreqs[:,:,freq_idx,:]\n",
    "                 scores = cross_val_multiscore(se, X=X, y=y, cv=cv_folds, verbose=0)\n",
    "                 scores = np.mean(scores, axis=0)\n",
    "                 scores_per_freq[idx, :] = scores\n",
    "\n",
    "                 se.fit(X, y)\n",
    "                 coef = get_coef(se, 'patterns_', inverse_transform=True)\n",
    "                 coefs_per_freq[idx, :, :] = coef\n",
    "                 \n",
    "            all_scores.append(scores_per_freq)\n",
    "            all_coef.append(coef)\n",
    "\n",
    "        sub_scores.append(np.asarray(all_scores).mean(axis=0))\n",
    "        sub_coef.append(np.asarray(all_coef).mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subID, part_epo, signaltype, conditions, event_dict,\n",
    "             batch_size=1, smooth_winsize=1):\n",
    "    tfr_dict = defaultdict(dict)\n",
    "    for cond in conditions:\n",
    "        tfr_dict[cond] = load_singletrialtfr(subID,\n",
    "                                             condition=cond,\n",
    "                                             pwr_style='induced',\n",
    "                                             part_epo=part_epo,\n",
    "                                             baseline=None,\n",
    "                                             mode=None)\n",
    "\n",
    "        times = tfr_dict[conditions[0]].times\n",
    "        freqs = tfr_dict[conditions[0]].freqs\n",
    "\n",
    "    # Setup data:\n",
    "    if batch_size > 1:\n",
    "        batches = defaultdict(list)\n",
    "        for cond in conditions:\n",
    "            batches[cond] = batch_trials(tfr_dict[cond], batch_size)\n",
    "            batches[cond] = np.asarray([b.data for b in batches[cond]])\n",
    "\n",
    "        X = np.concatenate([batches[cond].data for cond in conditions], axis=0)\n",
    "        n_ = {cond: batches[cond].shape[0] for cond in conditions}\n",
    "\n",
    "    else:\n",
    "        X = mne.concatenate_epochs([tfr_dict[cond] for cond in conditions])\n",
    "        X = X.data\n",
    "        n_ = {cond: len(tfr_dict[cond]) for cond in conditions}\n",
    "\n",
    "    if smooth_winsize > 1:\n",
    "        X, times_n = avg_time(X, smooth_winsize, times=times)\n",
    "    else:\n",
    "        times_n = times\n",
    "\n",
    "    y = np.r_[np.zeros(n_[conditions[0]]),\n",
    "              np.concatenate([(np.ones(n_[conditions[i]]) * i)\n",
    "                              for i in np.arange(1, len(conditions))])]\n",
    "\n",
    "    return X, y, times_n, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode(sub_list_str, conditions, part_epo='fulllength', signaltype='collapsed', freqs_decod='all',\n",
    "           event_dict=config.event_dict, n_rep_sub=100, shuffle_labels=False,\n",
    "           batch_size=1, smooth_winsize=1, save_single_rep_scores=False,\n",
    "           save_scores=True, save_patterns=False, overwrite=False):\n",
    "\n",
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    scoring = 'accuracy'\n",
    "    cv_folds = 5\n",
    "\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        LinearModel(LogisticRegression(solver='liblinear',\n",
    "                                                       penalty='l2',\n",
    "                                                       random_state=42,\n",
    "                                                       verbose=False)))\n",
    "\n",
    "    se = SlidingEstimator(clf,\n",
    "                          scoring=scoring,\n",
    "                          n_jobs=-2,\n",
    "                          verbose=0)\n",
    "\n",
    "    sub_scores = list()\n",
    "    sub_scores_per_rep = list()\n",
    "    sub_coef = list()\n",
    "    completed_subs = list()\n",
    "\n",
    "    for subID in sub_list_str:\n",
    "        print(f'### RUNING SUBJECT {subID}')\n",
    "        all_scores = list()\n",
    "        all_coef = list()\n",
    "        for i in np.arange(n_rep_sub):\n",
    "            X_allfreqs, y, times_n, freqs = get_data(subID,\n",
    "                                                    part_epo=part_epo,\n",
    "                                                    signaltype=signaltype,\n",
    "                                                    conditions=conditions,\n",
    "                                                    event_dict=event_dict,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    smooth_winsize=smooth_winsize)\n",
    "            if freqs_decod == 'all':\n",
    "                freqs_select = freqs\n",
    "            else:\n",
    "                freqs_select = [f for f in freqs_decod if f in freqs]\n",
    "                if len(freqs_select) < len(freqs_decod):\n",
    "                    f_not_found = [f for f in freqs_decod if f not in freqs]\n",
    "                    ending = 'y' if (len(f_not_found) == 1) else 'ies'\n",
    "                    raise ValueError(f'Frequenc{ending} not present in data: {f_not_found}')\n",
    "            if shuffle_labels:\n",
    "                np.random.shuffle(y)\n",
    "            for i in np.unique(y):\n",
    "                print(f'Size of class {i}: {np.sum(y == i)}\\n')\n",
    "            \n",
    "            scores_per_freq = np.zeros((len(freqs_select), len(times_n)))\n",
    "            coefs_per_freq = np.zeros((len(freqs_select), X_allfreqs.shape[-3], X_allfreqs.shape[-1]))\n",
    "            for idx, freq in enumerate(freqs_select):\n",
    "                 print(f'#### Frequency {idx+1} from {len(freqs_select)}')\n",
    "                 freq_idx = list(freqs).index(freq)\n",
    "                 X = X_allfreqs[:,:,freq_idx,:]\n",
    "                 scores = cross_val_multiscore(se, X=X, y=y, cv=cv_folds, verbose=0)\n",
    "                 scores = np.mean(scores, axis=0)\n",
    "                 scores_per_freq[idx, :] = scores\n",
    "\n",
    "                 se.fit(X, y)\n",
    "                 coef = get_coef(se, 'patterns_', inverse_transform=True)\n",
    "                 coefs_per_freq[idx, :, :] = coef\n",
    "                 \n",
    "            all_scores.append(scores_per_freq)\n",
    "            all_coef.append(coef)\n",
    "\n",
    "        sub_scores.append(np.asarray(all_scores).mean(axis=0))\n",
    "        sub_coef.append(np.asarray(all_coef).mean(axis=0))\n",
    "\n",
    "        # save shizzle:\n",
    "#         if save_single_rep_scores:\n",
    "#             if len(sub_scores_per_rep) == 0:\n",
    "#                 sub_scores_per_rep = np.asarray(all_scores)\n",
    "#             else:\n",
    "#                 sub_scores_per_rep = np.concatenate([sub_scores_per_rep,\n",
    "#                                                     np.asarray(all_scores)],\n",
    "#                                                     axis=0)\n",
    "\n",
    "#             fpath = op.join(config.path_decod_temp, contrast_str, 'single_rep_data')\n",
    "#             helpers.chkmk_dir(fpath)\n",
    "#             fname = op.join(fpath,\n",
    "#                             f'reps{n_rep_sub}_' \\\n",
    "#                             f'swin{smooth_winsize}_batchs{batch_size}.npy')\n",
    "#             np.save(fname, sub_scores_per_rep)\n",
    "#             np.save(fname[:-4] + '__times' + '.npy', times_n)\n",
    "#             del(fpath, fname)\n",
    "                 \n",
    "        # save info:\n",
    "        if (save_scores or save_patterns):\n",
    "            completed_subs.append(subID)\n",
    "            info_dict = {'subs': completed_subs,\n",
    "                         'freqs': freqs,\n",
    "                         'cv_folds': cv_folds, \n",
    "                         'reps': n_rep_sub,\n",
    "                         'batch_size': batch_size, \n",
    "                         'smooth_winsize': smooth_winsize, \n",
    "                         'scoring': scoring}\n",
    "            if len(sub_list_str) > 1:\n",
    "                 sub_folder = '-'.join(sub_list_str[0], sub_list_str[-1])\n",
    "            else:\n",
    "                 sub_folder = sub_list_str[0]\n",
    "                 \n",
    "            fpath = op.join(config.path_decod_tfr, 'wavelet', part_epo, signaltype, contrast_str, sub_folder)\n",
    "            if (op.exists(fpath) and not overwrite):\n",
    "                path_save = op.join(config.path_decod_tfr, 'wavelet', part_epo, signaltype, contrast_str, \n",
    "                                    sub_folder + datetime_str)\n",
    "            else:\n",
    "                path_save = fpath\n",
    "            helpers.chkmk_dir(path_save)\n",
    "            fname = op.join(path_save, 'info.json')\n",
    "            with open(fname, 'w+') as outfile:  \n",
    "                json.dump(info_dict, outfile)\n",
    "                 \n",
    "                 \n",
    "        # save accuracies:\n",
    "        if save_scores:\n",
    "            sub_scores_ = np.asarray(sub_scores)\n",
    "            fpath = op.join(path_save, 'scores')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "            np.save(fname, sub_scores_)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', times_n)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freqs_select)\n",
    "            del(fpath, fname)\n",
    "\n",
    "\n",
    "        # save patterns:\n",
    "        if save_patterns:\n",
    "            sub_patterns = np.asarray(sub_coef)\n",
    "            fpath = op.join(path_save, 'patterns')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'patterns_per_sub.npy')\n",
    "            np.save(fname, sub_patterns)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', times_n)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freqs_select)\n",
    "            del(fpath, fname)\n",
    "                 \n",
    "    return sub_scores, sub_coef, times_n, freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RUNING SUBJECT VME_S01\n",
      "Reading /draco/ptmp/fklotzsche/Experiments/vMemEcc/Data/DataMNE/EEG/08_tfr/induced/tfr_lists/fulllength/VME_S01-collapsed-singletrialTFRs-tfr.h5 ...\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Reading /draco/ptmp/fklotzsche/Experiments/vMemEcc/Data/DataMNE/EEG/08_tfr/induced/tfr_lists/fulllength/VME_S01-collapsed-singletrialTFRs-tfr.h5 ...\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "Size of class 0.0: 11\n",
      "\n",
      "Size of class 1.0: 10\n",
      "\n",
      "#### Frequency 1 from 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4562631d6281473899b3597b0c2e00ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    2.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    2.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09d6eeb3ffd47cf9e03ced1c164c293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06778096b3e451da4945b210489db7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdac429b3a77451bb2fef62afe95f08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750b1ccf1e4b4c7bb2aaa2b8f7e52bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae91c81222045918b2aa9cb5de807da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Frequency 2 from 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffeab1b490ce43d7904ede7ffb9ddb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53bb04e6bc9470e8f529dafec70ea7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5415955ba6904ee5a376be86af1c825d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94c09f6a26341658ab1a1e332fc1acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e5f6cd6cf34f509ac5bb994dcaf6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=63)]: Using backend LokyBackend with 63 concurrent workers.\n",
      "[Parallel(n_jobs=63)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=63)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=63)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  32 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=63)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba60bd31e8914a10b22075d39b2e977a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting SlidingEstimator', max=40.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating dir: /draco/ptmp/fklotzsche/Experiments/vMemEcc/Data/DataMNE/EEG/10_tfr_decoding/wavelet/fulllength/collapsed/LoadLowEccL_vs_LoadHighEccL/VME_S01\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-330804ee1a4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   \u001b[0msave_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                   save_patterns=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-ca3fe6aa3d23>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(sub_list_str, conditions, part_epo, signaltype, freqs_decod, event_dict, n_rep_sub, shuffle_labels, batch_size, smooth_winsize, save_single_rep_scores, save_scores, save_patterns, overwrite)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'info.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "sub_list = np.setdiff1d(np.arange(1, 28), config.ids_missing_subjects +\n",
    "                        config.ids_excluded_subjects)               \n",
    "sub_list_str = ['VME_S%02d' % sub for sub in sub_list]\n",
    "\n",
    "res_load = decode(sub_list_str[:1], ['LoadLowEccL', 'LoadHighEccL'], \n",
    "                  event_dict=config.event_dict, \n",
    "                  freqs_decod=[10, 12], \n",
    "                  n_rep_sub=1, \n",
    "                  batch_size=10, \n",
    "                  smooth_winsize=50,\n",
    "                  overwrite=True, \n",
    "                  save_scores=True,\n",
    "                  save_patterns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccs = load_singletrialtfr('VME_S01', 'EccS')\n",
    "eccm = load_singletrialtfr('VME_S01', 'EccM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9a958dbbec3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfreqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'freqs' is not defined"
     ]
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
