{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing IV: data cleaning and rejection with `autoreject`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `autoreject`(local) to interpolate bad channels (per epoch) and reject bad (i.e., unrepairable) epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as op\n",
    "import sys\n",
    "import numpy as np\n",
    "import autoreject\n",
    "import mne\n",
    "from library import config, helpers, preprocess\n",
    "\n",
    "\n",
    "def norm_vec(x):\n",
    "    return x / np.sqrt(np.sum(x**2))\n",
    "\n",
    "# parse  args:\n",
    "if (len(sys.argv) > 1):\n",
    "    helpers.print_msg('Running Job Nr. ' + sys.argv[1])\n",
    "    job_nr = int(sys.argv[1])\n",
    "else:\n",
    "    job_nr = None\n",
    "\n",
    "## Full procedure:\n",
    "sub_list = np.setdiff1d(np.arange(1,config.n_subjects_total+1), config.ids_missing_subjects)\n",
    "\n",
    "#sub_list = [7, 21, 22, 23, 24, 25, 26, 27] \n",
    "\n",
    "sub_list_str = ['VME_S%02d' % sub for sub in sub_list]\n",
    "\n",
    "if job_nr is not None:\n",
    "    sub_list_str = [sub_list_str[job_nr]]\n",
    "for epo_part in ['stimon', 'cue', 'fulllength']: # []: # \n",
    "    for subID in sub_list_str:\n",
    "        fname = '-'.join([subID, epo_part, 'postICA'])\n",
    "        try:\n",
    "            path_in = op.join(config.paths['03_preproc-ica'], 'cleaneddata', '0.1', epo_part)\n",
    "            data_pre = helpers.load_data(fname, path_in, '-epo')\n",
    "        except FileNotFoundError:\n",
    "            print(f'No data for {subID}.')\n",
    "            continue\n",
    "            \n",
    "        data_bl = data_pre.copy().apply_baseline((-config.times_dict['bl_dur_erp'], 0)) \n",
    "        \n",
    "        ars = []\n",
    "        reject_logs = []\n",
    "        rand_ints = [30,7,19,88,307,198,8,3,0,71988]\n",
    "        for rs in rand_ints:\n",
    "            data_post, ar, reject_log = preprocess.clean_with_ar_local(subID,\n",
    "                                                                       data_bl,\n",
    "                                                                       epo_part=epo_part,\n",
    "                                                                       n_jobs=70,\n",
    "                                                                       save_to_disc=False,\n",
    "                                                                       rand_state=rs)\n",
    "            ars.append(ar)\n",
    "            reject_logs.append(reject_log)\n",
    "        \n",
    "        all_badepos = np.stack([rl.bad_epochs for rl in reject_logs])\n",
    "        avg_badepos = all_badepos.mean(axis=0)\n",
    "\n",
    "        # sims = [np.dot(avg_rl.flatten(), rl.flatten()) for rl in all_rls]\n",
    "        sims = [np.dot(norm_vec(avg_badepos), norm_vec(be)) for be in all_badepos]\n",
    "\n",
    "        idx_max = np.argmax(sims)\n",
    "        \n",
    "        path_save = op.join(config.paths['03_preproc-ar'], '0.1', 'robust')\n",
    "        helpers.chkmk_dir(path_save)\n",
    "        data_post, ar, reject_log = preprocess.clean_with_ar_local(subID,\n",
    "                                                                   data_bl,\n",
    "                                                                   epo_part=epo_part,\n",
    "                                                                   n_jobs=70,\n",
    "                                                                   save_to_disc=True,\n",
    "                                                                   ar_path=path_save,\n",
    "                                                                   rand_state=rand_ints[idx_max])\n",
    "\n",
    "        file_diag = op.join(path_save, epo_part, 'info.txt')\n",
    "        n_bad_epos = [sum(rl.bad_epochs) for rl in reject_logs]\n",
    "        n_epos_min = np.min(n_bad_epos)\n",
    "        n_epos_max = np.max(n_bad_epos)\n",
    "        with open(file_diag, 'a+') as f:\n",
    "            f.write(f'{subID};{n_epos_min};{n_epos_max};{n_bad_epos};{n_bad_epos[idx_max]}\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
