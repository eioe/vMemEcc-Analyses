{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0419f731",
   "metadata": {},
   "source": [
    "# Data Preparation: setting up the data for further processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbf9c758",
   "metadata": {},
   "source": [
    "Prepares EEG data for further processing steps & extract events. \n",
    "\n",
    "- Calculate bipolar EOG channels\n",
    "- Set channel type of ECG channel\n",
    "- extract events (in a robust way, fixing some minor issues that happened during a few recordings)\n",
    "- save the events (and indices of bad epochs) to disk\n",
    "\n",
    "**If you want to work with clean data right away (recommended), skip this step and load the clean files from the `01_prepared` folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdbe971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study path is set to: /raven/ptmp/fklotzsche/Experiments/vMemEcc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import mne\n",
    "from pathlib import Path\n",
    "from library import helpers, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a41b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_events(subID):\n",
    "    \"\"\"\n",
    "    Read raw data and extract events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subID : str\n",
    "        Subject ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    raw : mne.io.Raw\n",
    "        Raw data.\n",
    "    events : array\n",
    "        Events.\n",
    "    event_id : dict\n",
    "        Event IDs.\n",
    "    \"\"\"\n",
    "    fname_inp = op.join(config.paths[\"00_raw\"], subID + \"-raw.fif\")\n",
    "    raw = mne.io.read_raw_fif(fname_inp)\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "    return raw, events, event_id\n",
    "\n",
    "\n",
    "def save_events(subID, events, event_id, bad_epos, epo_part):\n",
    "    \"\"\"\n",
    "    Save events and event IDs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subID : str\n",
    "        Subject ID.\n",
    "    events : array\n",
    "        Events.\n",
    "    event_id : dict\n",
    "        Event IDs.\n",
    "    bad_epos : list\n",
    "        Bad epochs.\n",
    "    epo_part : str\n",
    "        Epoch part.\n",
    "    \"\"\"\n",
    "    fname_eve = op.join(\n",
    "        config.paths[\"01_prepared-events\"], \"-\".join([subID, epo_part, \"eve.fif\"])\n",
    "    )\n",
    "    mne.write_events(fname_eve, events)\n",
    "    fname_eve_id = op.join(\n",
    "        config.paths[\"01_prepared-events\"], \"-\".join([subID, \"event_id.pkl\"])\n",
    "    )\n",
    "    if event_id is not None:\n",
    "        with open(fname_eve_id, \"wb\") as f:\n",
    "            pickle.dump(event_id, f)\n",
    "    fname_bad_epos = op.join(\n",
    "        config.paths[\"01_prepared-events\"], \"-\".join([subID, \"bad_epos_recording.pkl\"])\n",
    "    )\n",
    "    with open(fname_bad_epos, \"wb\") as f:\n",
    "        pickle.dump(bad_epos, f)\n",
    "\n",
    "\n",
    "def calc_eog_chans(data_raw):\n",
    "    \"\"\"\n",
    "    Calculate and add bipolar HEOG and VEOG channels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_raw : mne.io.Raw\n",
    "        Raw data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_raw : mne.io.Raw\n",
    "        Raw data with added EOG channels.\n",
    "    \"\"\"\n",
    "    # if IO1 is not present, the old labels shall be used\n",
    "    if not \"IO1\" in data_raw.ch_names:\n",
    "        rn_ch_dict = {\"AF7\": \"IO1\", \"AF8\": \"IO2\", \"FT9\": \"LO1\", \"FT10\": \"LO2\"}\n",
    "        data_raw.rename_channels(rn_ch_dict)\n",
    "        print(\"renaming eog channels.\")\n",
    "\n",
    "    ## which labels were given to EOG electrodes:\n",
    "    # 'vertical_chans' :\n",
    "    #        'left': ['Fp1', 'IO1'],\n",
    "    #        'right': ['Fp2', 'IO2']\n",
    "    # 'horizontal_chans' :\n",
    "    #        'left': ['LO1'],\n",
    "    #        'right': ['LO2']\n",
    "\n",
    "    # For a few subjects electrodes 'Fp1' and 'IO1' were mistakenly exchanged.\n",
    "    # Let's find out for which ones and repair it:\n",
    "\n",
    "    picks = [\"Fp1\", \"Fp2\", \"IO1\", \"IO2\", \"LO1\", \"LO2\"]\n",
    "    rr = (\n",
    "        data_raw.load_data()\n",
    "        .copy()\n",
    "        .pick_channels(picks)\n",
    "        .filter(l_freq=1, h_freq=5, picks=[\"eeg\", \"misc\"], verbose=False)\n",
    "    )\n",
    "    # Create pseudo epochs to loop over:\n",
    "    events = mne.make_fixed_length_events(rr, duration=20)\n",
    "    epochs = mne.Epochs(rr, events, tmin=0.0, tmax=20, baseline=(0, 1), verbose=False)\n",
    "    epochs.load_data().reorder_channels(picks)\n",
    "    # For each epoch we calculate the correlations between all EOG channels and store it\n",
    "    holder = []\n",
    "    for epo in epochs:\n",
    "        epo = epo - epo.copy().mean(axis=1, keepdims=True)\n",
    "        tmp = np.corrcoef(epo)\n",
    "        holder.append(tmp)\n",
    "\n",
    "    res = np.stack(holder).mean(axis=0)\n",
    "\n",
    "    # correlations of \"Fp1\" (what could be \"IO1\")\n",
    "    idx_fp1 = epochs.ch_names.index(\"Fp1\")\n",
    "    corrs_fp1 = res[idx_fp1, :]\n",
    "    # corr with itself is ofc largest, so we put it away\n",
    "    corrs_fp1[idx_fp1] = -999\n",
    "    # now get which other chan it correlates most with\n",
    "    idx_corrmax = np.argmax(corrs_fp1)\n",
    "    chan_corrmax = epochs.ch_names[idx_corrmax]\n",
    "    helpers.print_msg(\n",
    "        f\"What we think is Fp1 actually correlates highly with {chan_corrmax} (r = {str(np.max(corrs_fp1))})).\"\n",
    "    )\n",
    "\n",
    "    if not chan_corrmax == \"Fp2\":\n",
    "        helpers.print_msg(\"Swopping channels IO1 and Fp1.\")\n",
    "        tmp = data_raw.get_data(picks=[\"Fp1\", \"IO1\"])\n",
    "        data_raw[\"Fp1\"] = tmp[1]\n",
    "        data_raw[\"IO1\"] = tmp[0]\n",
    "\n",
    "    # calculate bipolar EOG chans:\n",
    "    data_raw.load_data()\n",
    "    dataL = data_raw.get_data([\"Fp1\"]) - data_raw.get_data([\"IO1\"])\n",
    "    dataR = data_raw.get_data([\"Fp2\"]) - data_raw.get_data([\"IO2\"])\n",
    "    dataVEOG = np.stack((dataL, dataR), axis=0).mean(0)\n",
    "\n",
    "    dataHEOG = data_raw.get_data([\"LO1\"]) - data_raw.get_data([\"LO2\"])\n",
    "    dataEOG = np.concatenate((dataVEOG, dataHEOG), axis=0)\n",
    "    info = mne.create_info(\n",
    "        ch_names=[\"VEOG\", \"HEOG\"], sfreq=raw.info[\"sfreq\"], ch_types=[\"eog\", \"eog\"]\n",
    "    )\n",
    "    rawEOG = mne.io.RawArray(dataEOG, info=info)\n",
    "    data_raw.add_channels([rawEOG], force_update_info=True)\n",
    "    # set chan type of original channels to EEG:\n",
    "    ch_type_dict = {\"IO1\": \"misc\", \"IO2\": \"misc\", \"LO1\": \"misc\", \"LO2\": \"misc\"}\n",
    "    data_raw.set_channel_types(ch_type_dict)\n",
    "\n",
    "    return data_raw\n",
    "\n",
    "\n",
    "def set_ecg_chan(data_raw):\n",
    "    \"\"\"\n",
    "    Set ECG channel (here: setting it to lowercase).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_raw : mne.io.Raw\n",
    "        Raw data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_raw : mne.io.Raw\n",
    "        Raw data with added ECG channel.\n",
    "    \"\"\"\n",
    "    ch_type_dict = {\"ECG\": \"ecg\"}\n",
    "    data_raw.set_channel_types(ch_type_dict)\n",
    "\n",
    "\n",
    "def setup_event_structures(events_, event_id_, srate_):\n",
    "    \"\"\"\n",
    "    Setup event structures.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    events_ : array\n",
    "        Events.\n",
    "    event_id_ : dict\n",
    "        Event IDs.\n",
    "    srate_ : float\n",
    "        Sampling rate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    events_fix_ : array\n",
    "        Events of fixation cue onset.\n",
    "    events_cue_ : array\n",
    "        Events of lateralized cue onset.\n",
    "    events_stimon_ : array\n",
    "        Events of memory stimulus onset.\n",
    "    bad_epos : array\n",
    "        Bad epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define relevant events:\n",
    "    targ_evs_orig = [i for i in np.arange(150, 174)]\n",
    "    targ_evs = [event_id_[\"Stimulus/S%03d\" % ss] for ss in targ_evs_orig]\n",
    "\n",
    "    epo_keys = [\"CueL\", \"CueR\", \"LoadLow\", \"LoadHigh\", \"EccS\", \"EccM\", \"EccL\"]\n",
    "\n",
    "    event_dict = {key: [] for key in epo_keys}\n",
    "    for ev in targ_evs:\n",
    "        ev0 = ev - 150\n",
    "        if (ev0 % 2) == 0:\n",
    "            event_dict[\"CueL\"].append(str(ev))\n",
    "        else:\n",
    "            event_dict[\"CueR\"].append(str(ev))\n",
    "\n",
    "        if (ev0 % 8) < 4:\n",
    "            event_dict[\"LoadLow\"].append(str(ev))\n",
    "        else:\n",
    "            event_dict[\"LoadHigh\"].append(str(ev))\n",
    "\n",
    "        if (ev0 % 24) < 8:\n",
    "            event_dict[\"EccS\"].append(str(ev))\n",
    "        elif (ev0 % 24) > 15:\n",
    "            event_dict[\"EccL\"].append(str(ev))\n",
    "        else:\n",
    "            event_dict[\"EccM\"].append(str(ev))\n",
    "\n",
    "    # clean from double markers in restarted trials:\n",
    "    # same routine as in ET analysis\n",
    "\n",
    "    # temporary list of trial onsets (fixation Onsets) and StimOnsets:\n",
    "    tmp_ev_fix = np.array([ev for ev in events_ if ev[2] in targ_evs])\n",
    "    stimon_times = np.array(\n",
    "        [ev[0] for ev in events_ if ev[2] == event_id_[\"Stimulus/S  2\"]]\n",
    "    )\n",
    "    for i in range(1, len(tmp_ev_fix)):\n",
    "        # We know that for restarted trials the same trial type comes 2x in a row:\n",
    "        if tmp_ev_fix[i, 2] == tmp_ev_fix[i - 1, 2]:\n",
    "            times_between = np.arange(tmp_ev_fix[i - 1, 0], tmp_ev_fix[i, 0])\n",
    "            # if no StimOnset between these two markers:\n",
    "            if not len(np.intersect1d(times_between, stimon_times)) > 0:\n",
    "                # we know that this was a restarted trial, and we overwrite all events between the two\n",
    "                # relevant markers:\n",
    "                idx = np.in1d(events_[:, 0], times_between)\n",
    "                for ee in events_[idx]:\n",
    "                    ev_name = [n for n, v in event_id_.items() if v == ee[2]]\n",
    "                    print(\"Trial restarted: Overwriting event -- \" + str(ev_name))\n",
    "                events_[idx, 2] = 999\n",
    "\n",
    "    # crop off all markers before first and after last exp block:\n",
    "    key_b1_start = \"Stimulus/S208\"\n",
    "    if key_b1_start in event_id_:\n",
    "        trig_b1_start = event_id_[key_b1_start]\n",
    "    else:\n",
    "        trig_b1_start = events[0][2]  # use first event ever in case of doubt\n",
    "        print(\"Warning: No event START BLOCK01 found. Using first event in structure.\")\n",
    "    # same for end of last block:\n",
    "    key_b10_end = \"Stimulus/S247\"\n",
    "    if key_b10_end in event_id_:\n",
    "        trig_b10_end = event_id_[key_b10_end]\n",
    "    else:\n",
    "        trig_b10_end = events[-1][2]\n",
    "        print(\"Warning: No event END BLOCK10 found. Using last event in structure.\")\n",
    "    rel_evs = events_[:, 2]\n",
    "    idx_start = np.where(rel_evs == trig_b1_start)[0][0]  # use first element\n",
    "    idx_end = np.where(rel_evs == trig_b10_end)[0][\n",
    "        -1\n",
    "    ]  # use last element to get last instance\n",
    "    events_ = events_[idx_start : idx_end + 1, :]\n",
    "\n",
    "    # set up event arrays:\n",
    "    events_fix_ = np.array([ev for ev in events_ if ev[2] in targ_evs])\n",
    "    # add duration of blinking interval:\n",
    "    events_fix_[:, 0] = events_fix_[:, 0] + config.times_dict[\"blink_dur\"] * srate_\n",
    "\n",
    "    events_cue_ = np.array(\n",
    "        [ev for ev in events_ if ev[2] == event_id_[\"Stimulus/S  1\"]]\n",
    "    )\n",
    "    events_stimon_ = np.array(\n",
    "        [ev for ev in events_ if ev[2] == event_id_[\"Stimulus/S  2\"]]\n",
    "    )\n",
    "\n",
    "    bad_epos = dict()\n",
    "    # Check if for all relevant events 720 instances were found:\n",
    "    if any(np.array([len(events_fix_), len(events_cue_), len(events_stimon_)]) < 720):\n",
    "\n",
    "        # Missing triggers that code for the trial type are tricky. It's better to fix that manually instead of silently tring to fix it.\n",
    "        if len(events_fix_) != 720:\n",
    "            raise ValueError(\n",
    "                \"There is a trigger missing that codes for the trial type. You have to fix this manually, I'm afraid!\"\n",
    "            )\n",
    "\n",
    "        # For CueOnset triggers we can check their distance to the trial onsets (ie, fixation onset triggers).\n",
    "        # If no stimonset trigger is found in the relevant time window, this is probably the trial where something went wrong.\n",
    "        if len(events_cue_) != 720:\n",
    "            idx = np.argwhere(\n",
    "                [\n",
    "                    np.min(np.abs(ev[0] - events_cue_[:, 0]))\n",
    "                    > (config.times_dict[\"fix_dur\"] + 0.1) * srate\n",
    "                    for ev in events_fix_\n",
    "                ]\n",
    "            )\n",
    "            if len(idx) != (720 - len(events_cue_)):\n",
    "                raise ValueError(\n",
    "                    \"There is a timing issue apart from missing triggers. Check your triggers manually!\"\n",
    "                )\n",
    "            else:\n",
    "                for i in idx:\n",
    "                    print(\n",
    "                        'Replacing missing trigger for Cue and adding to \"bads\" list.'\n",
    "                    )\n",
    "                    new_ev = [\n",
    "                        int(\n",
    "                            events_fix_[i[0], 0] + config.times_dict[\"fix_dur\"] * srate_\n",
    "                        ),\n",
    "                        0,\n",
    "                        event_id_[\"Stimulus/S  1\"],\n",
    "                    ]\n",
    "                    events_tmp = np.vstack([events_cue_, new_ev])\n",
    "                    # sort events ascending in time:\n",
    "                    events_cue_ = events_tmp[events_tmp[:, 0].argsort()]\n",
    "            bad_epos[\"cue\"] = idx.flatten()\n",
    "\n",
    "        # For StimOnset triggers we can check their distance to the trial onsets (ie, fixation onset triggers).\n",
    "        # If no stimonset trigger is found in the relevant time window, this is probably the trial where something went wrong.\n",
    "        if len(events_stimon_) != 720:\n",
    "            idx = np.argwhere(\n",
    "                [\n",
    "                    np.min(np.abs(ev[0] - events_stimon_[:, 0]))\n",
    "                    > (\n",
    "                        config.times_dict[\"fix_dur\"]\n",
    "                        + config.times_dict[\"cue_dur\"]\n",
    "                        + 0.1\n",
    "                    )\n",
    "                    * srate\n",
    "                    for ev in events_fix_\n",
    "                ]\n",
    "            )\n",
    "            if len(idx) != (720 - len(events_stimon_)):\n",
    "                raise ValueError(\n",
    "                    \"There is a timing issue apart from missing triggers. Check your triggers manually!\"\n",
    "                )\n",
    "            else:\n",
    "                for i in idx:\n",
    "                    print(\n",
    "                        'Replacing missing trigger for StimOnset and adding to \"bads\" list.'\n",
    "                    )\n",
    "                    new_ev = [\n",
    "                        int(\n",
    "                            events_fix_[i[0], 0]\n",
    "                            + (\n",
    "                                config.times_dict[\"fix_dur\"]\n",
    "                                + config.times_dict[\"cue_dur\"]\n",
    "                            )\n",
    "                            * srate_\n",
    "                        ),\n",
    "                        0,\n",
    "                        event_id_[\"Stimulus/S  2\"],\n",
    "                    ]\n",
    "                    events_tmp = np.vstack([events_stimon_, new_ev])\n",
    "                    # sort events ascending in time:\n",
    "                    events_stimon_ = events_tmp[events_tmp[:, 0].argsort()]\n",
    "            bad_epos[\"stimon\"] = idx.flatten()\n",
    "\n",
    "    # Make sure that trials are in the same order (sorted by time)\n",
    "    events_fix_ = events_fix_[events_fix_[:, 0].argsort()]\n",
    "    events_stimon_ = events_stimon_[events_stimon_[:, 0].argsort()]\n",
    "    events_cue_ = events_cue_[events_cue_[:, 0].argsort()]\n",
    "    assert len(events_fix_) == len(events_stimon_) == len(events_cue_)\n",
    "\n",
    "    # Add trial type info to last column:\n",
    "    events_stimon_[:, 2] = events_fix_[:, 2]\n",
    "    events_cue_[:, 2] = events_fix_[:, 2]\n",
    "\n",
    "    return events_fix_, events_cue_, events_stimon_, bad_epos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Full procedure:\n",
    "sub_list = np.setdiff1d(\n",
    "    np.arange(1, config.n_subjects_total + 1), config.ids_missing_subjects\n",
    ")\n",
    "sub_list_str = [\"VME_S%02d\" % sub for sub in sub_list]\n",
    "\n",
    "## to run a single subject, modify and uncomment the following line:\n",
    "# sub_list_str = ['VME_S01']\n",
    "\n",
    "# sub_list = np.array([sub_list_str[job_nr]])\n",
    "\n",
    "for idx, subID in enumerate(sub_list_str):\n",
    "    helpers.print_msg(\"Processing subject \" + subID + \".\")\n",
    "\n",
    "    # Get data:\n",
    "    raw, events, event_id = get_data_and_events(subID)\n",
    "\n",
    "    # Calculate EOG channels & set chan type:\n",
    "    raw = calc_eog_chans(raw)\n",
    "\n",
    "    # Set ECG chan type:\n",
    "    set_ecg_chan(raw)\n",
    "\n",
    "    # Save prepared data:\n",
    "    helpers.save_data(\n",
    "        raw, subID + \"-prepared\", config.paths[\"01_prepared\"], append=\"-raw\"\n",
    "    )\n",
    "\n",
    "    print(\"***Saving events:***\")\n",
    "\n",
    "    # Extract and save events:\n",
    "    srate = raw.info[\"sfreq\"]\n",
    "    events_fix, events_cue, events_stimon, bad_epos = setup_event_structures(\n",
    "        events, event_id, srate\n",
    "    )\n",
    "    save_events(\n",
    "        subID, events_stimon, event_id=event_id, bad_epos=bad_epos, epo_part=\"stimon\"\n",
    "    )\n",
    "    save_events(\n",
    "        subID, events_cue, event_id=None, bad_epos=bad_epos, epo_part=\"cue\"\n",
    "    )  # enough to save event_id once\n",
    "    save_events(subID, events_fix, event_id=None, bad_epos=bad_epos,\n",
    "                epo_part=\"fix\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
