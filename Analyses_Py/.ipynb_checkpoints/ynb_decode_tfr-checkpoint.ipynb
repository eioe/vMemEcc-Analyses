{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test, f_mway_rm, f_threshold_mway_rm\n",
    "from mne.decoding import CSP\n",
    "from library import helpers, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epos(subID, part_epo, signaltype, condition, event_dict):\n",
    "    \"\"\"Load a set of specified epochs.\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    subID : str\n",
    "        Subject identifier (eg, 'VME_S05')\n",
    "    part_epo : str\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon'\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "    condition: str\n",
    "        Experimental condition. Combination of 'Ecc' and 'Load' (eg, 'LoadLow' or 'LoadLowEccS')\n",
    "    event_dict: dict\n",
    "        Dictionnary explaining the event codes. Normally this can be grabbed from config.event_dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mne.Epochs\n",
    "        Array of selected epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    if signaltype == 'uncollapsed':\n",
    "        fname = op.join(config.path_rejepo, subID + '-' + part_epo +\n",
    "                        '-postica-rejepo' + '-epo.fif')\n",
    "    elif signaltype in ['collapsed']:\n",
    "        fname = op.join(config.path_epos_sorted, part_epo, signaltype,\n",
    "                        subID + '-epo.fif')\n",
    "    else:\n",
    "        raise ValueError(f'Invalid value for \"signaltype\": {signaltype}')\n",
    "    epos = mne.read_epochs(fname, verbose=False)\n",
    "    epos = epos.pick_types(eeg=True)\n",
    "    uppers = [letter.isupper() for letter in condition]\n",
    "    if (np.sum(uppers) > 2):\n",
    "        cond_1 = condition[:np.where(uppers)[0][2]]\n",
    "        cond_2 = condition[np.where(uppers)[0][2]:]\n",
    "        selection = epos[event_dict[cond_1]][event_dict[cond_2]]\n",
    "    else:\n",
    "        selection = epos[event_dict[condition]]\n",
    "    return(selection)\n",
    "\n",
    "\n",
    "def get_sensordata(subID, part_epo, signaltype, conditions, event_dict):\n",
    "    \"\"\"Load a set of specified epochs for classification.\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    subID : str\n",
    "        Subject identifier (eg, 'VME_S05')\n",
    "    part_epo : str\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon'\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "    conditions: list\n",
    "        List of experimental conditions. Combination of 'Ecc' and 'Load' (eg, 'LoadLow' or 'LoadLowEccS')\n",
    "    event_dict: dict\n",
    "        Dictionnary explaining the event codes. Normally this can be grabbed from config.event_dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_epos: Epochs\n",
    "        Array of selected epochs, sorted by class (starting with class '0').\n",
    "    y: list\n",
    "        Sorted list of labels.\n",
    "    times_n: array, 1d\n",
    "        Times of the samples within the single epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    epos_dict = defaultdict(dict)\n",
    "    for cond in conditions:\n",
    "        epos_dict[cond] = get_epos(subID,\n",
    "                                   part_epo=part_epo,\n",
    "                                   signaltype=signaltype,\n",
    "                                   condition=cond,\n",
    "                                   event_dict=event_dict)\n",
    "\n",
    "    times = epos_dict[conditions[0]][0].copy().times\n",
    "\n",
    "    # Setup data:\n",
    "    X_epos = mne.concatenate_epochs([epos_dict[cond] for cond in conditions])\n",
    "    n_ = {cond: len(epos_dict[cond]) for cond in conditions}\n",
    "\n",
    "    times_n = times\n",
    "\n",
    "    y = np.r_[np.zeros(n_[conditions[0]]),\n",
    "              np.concatenate([(np.ones(n_[conditions[i]]) * i)\n",
    "                              for i in np.arange(1, len(conditions))])]\n",
    "\n",
    "    return X_epos, y, times_n\n",
    "\n",
    "\n",
    "def decode(sub_list_str, conditions, event_dict, reps = 1, save_scores = True, save_csp_patterns = True, \n",
    "           overwrite = False, part_epo = 'stimon', signaltype='collapsed'):\n",
    "    \"\"\"Apply CSP and LDA to perform binary classification from (the power) of epoched data.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Original code from: \n",
    "    https://mne.tools/stable/auto_examples/decoding/plot_decoding_csp_timefreq.html#\n",
    "    sphx-glr-auto-examples-decoding-plot-decoding-csp-timefreq-py\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_list_str : list of str\n",
    "        List of subject identifiers (eg, 'VME_S05')\n",
    "    conditions: list\n",
    "        List of experimental conditions that shall be compared/decoded. \n",
    "        Combination of 'Ecc' and 'Load' (eg, 'LoadLow' or 'LoadLowEccS')\n",
    "    event_dict: dict\n",
    "        Dictionnary explaining the event codes. Normally this can be grabbed from config.event_dict\n",
    "    reps: int \n",
    "        Number of repetions for the CV procedure.\n",
    "    save_scores: bool, optional\n",
    "        Shall the decoding scores be written to disk? (default is True).\n",
    "    save_patterns: bool, optional\n",
    "        Shall the CSP patterns be written to disk? (default is True).\n",
    "    overwrite : bool\n",
    "        Overwrite existing folders (True) or append current datetime to foldername (False). (default is False)\n",
    "    part_epo : str, optional\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon' (default is 'stimon').\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "                                                       (default is 'collapsed'.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf_scores_list: list\n",
    "        list of 2d arrays (freq x time) with the decoding scores per subject\n",
    "    centered_w_times: list\n",
    "        list with the times around which the decoding windows were centered.\n",
    "    \"\"\"\n",
    "    \n",
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    scoring = 'accuracy'\n",
    "    cv_folds = 5\n",
    "    n_components = 6\n",
    "    \n",
    "    csp = CSP(n_components=n_components, reg=None, log=True, norm_trace=False)\n",
    "    clf = make_pipeline(csp, LinearDiscriminantAnalysis())\n",
    "    \n",
    "    # Classification & time-frequency parameters\n",
    "    tmin = -0.5 # -config.times_dict['cue_dur']\n",
    "    tmax =  2.5  # config.times_dict['stim_dur'] + config.times_dict['retention_dur']\n",
    "    n_cycles = None  # how many complete cycles: used to define window size\n",
    "    w_size = 0.5\n",
    "    w_overlap = 0.5 # how much shall the windows overlap [value in [0,1]; 0: no overlap, 1: full overlap]\n",
    "    min_freq = 6\n",
    "    max_freq = 26\n",
    "    n_freqs = 10  # how many frequency bins to use\n",
    "\n",
    "    # Get datetime identifier for uniqure folder names (if not overwriting):\n",
    "    datetime_str = datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "\n",
    "    # Assemble list of frequency range tuples\n",
    "    freqs = np.linspace(min_freq, max_freq, n_freqs + 1)  # assemble frequencies\n",
    "    freq_ranges = list(zip(freqs[:-1], freqs[1:]))  # make freqs list of tuples# Setup list of seeds for the repetitions:\n",
    "    \n",
    "    # Setup list of seeds for the repetitions:\n",
    "    np.random.seed(seed=42)\n",
    "    rep_seeds = np.random.choice(range(10 * reps), reps)\n",
    "    \n",
    "\n",
    "    if ((n_cycles is not None) and (w_size is None)): \n",
    "        # Infer window spacing from the max freq and number of cycles to avoid gaps\n",
    "        window_spacing = (n_cycles / np.max(freqs) / 2.)\n",
    "        centered_w_times = np.arange(tmin, tmax, window_spacing)[1:]\n",
    "    elif (((w_size is not None)) and (n_cycles is None)): \n",
    "        assert 0 <= float(w_overlap or -1) < 1, f'Invalid value for w_overlap: {w_overlap}'\n",
    "        step_size = w_size * (1 - w_overlap)\n",
    "        centered_w_times = np.arange(tmin + (w_size / 2.), tmax - (w_size / 2) + 0.001, step_size)\n",
    "    else: \n",
    "        raise ValueError(f'Invalid combination of values for w_size and n_cylces. Exactly one must be None.')\n",
    "\n",
    "    n_windows = len(centered_w_times)\n",
    "\n",
    "    tf_scores_list = list()\n",
    "    tf_patterns_list = list()\n",
    "    completed_subs = list()\n",
    "    for subID in sub_list_str:\n",
    "        part_epo = part_epo\n",
    "\n",
    "        print(f'Running {subID}')\n",
    "\n",
    "        X_epos, y, t = get_sensordata(subID, part_epo, signaltype, conditions, event_dict)\n",
    "        n_channels = len(X_epos.ch_names)\n",
    "        # init scores\n",
    "        tf_scores = np.zeros((n_freqs, n_windows))\n",
    "        tf_scores_tmp = np.zeros((reps, n_freqs, n_windows))\n",
    "        tf_patterns = np.zeros((n_components, n_channels, n_freqs, n_windows))\n",
    "\n",
    "        # Loop through each frequency range of interest\n",
    "        for freq, (fmin, fmax) in enumerate(freq_ranges):\n",
    "\n",
    "            # print(f'Freq. {freq} of {len(freq_ranges)}')\n",
    "\n",
    "            if (w_size is None):\n",
    "                # Infer window size based on the frequency being used (default behavuior is to use a fixed w_size)\n",
    "                w_size = n_cycles / ((fmax + fmin) / 2.)  # in seconds\n",
    "\n",
    "            # Apply band-pass filter to isolate the specified frequencies\n",
    "            X_epos_filter = X_epos.copy().filter(fmin, fmax, n_jobs=-2, fir_design='firwin')\n",
    "\n",
    "            # Roll covariance, csp and lda over time\n",
    "            for t, w_time in enumerate(centered_w_times):\n",
    "\n",
    "                # Center the min and max of the window\n",
    "                w_tmin = w_time - w_size / 2.\n",
    "                w_tmax = w_time + w_size / 2.\n",
    "\n",
    "                # Crop data into time-window of interest\n",
    "                X = X_epos_filter.copy().crop(w_tmin, w_tmax).get_data()\n",
    "                \n",
    "                # Run repeated CV to estimate decoding score:\n",
    "                for rep, rand_state in enumerate(rep_seeds):\n",
    "                    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=rand_state)\n",
    "\n",
    "                    # Save mean scores over folds for each frequency and time window for this repetition\n",
    "                    tf_scores_tmp[rep, freq, t] = np.mean(cross_val_score(estimator=clf, X=X, y=y,\n",
    "                                                                          scoring='accuracy', cv=cv,\n",
    "                                                                          n_jobs=-2), axis=0)\n",
    "                if save_csp_patterns:\n",
    "                    # get CSP patterns - fitted to all data:\n",
    "                    csp.fit(X, y)\n",
    "                    patterns_ = getattr(csp, 'patterns_')\n",
    "                    tf_patterns[:, :, freq, t] = patterns_[:n_components, :]\n",
    "                \n",
    "        tf_scores = np.mean(tf_scores_tmp, axis=0)        \n",
    "        tf_scores_list.append(tf_scores)\n",
    "        tf_patterns_list.append(tf_patterns)\n",
    "\n",
    "        # save info:\n",
    "        if (save_scores or save_csp_patterns):\n",
    "            completed_subs.append(subID)\n",
    "            info_dict = {'subs': completed_subs,\n",
    "                         'tmin': tmin, \n",
    "                         'tmax': tmax, \n",
    "                         'n_cycles': n_cycles, \n",
    "                         'w_size': w_size,\n",
    "                         'w_overlap': w_overlap,\n",
    "                         'min_freq': min_freq, \n",
    "                         'max_freq': max_freq,\n",
    "                         'n_freqs': n_freqs,\n",
    "                         'cv_folds': cv_folds, \n",
    "                         'reps': reps,\n",
    "                         'scoring': scoring}\n",
    "            fpath = op.join(config.path_decod_tfr, part_epo, signaltype, contrast_str)\n",
    "            if (op.exists(fpath) and not overwrite):\n",
    "                path_save = op.join(config.path_decod_tfr, part_epo, signaltype, contrast_str + datetime_str)\n",
    "            else:\n",
    "                path_save = fpath\n",
    "            helpers.chkmk_dir(path_save)\n",
    "            fname = op.join(path_save, 'info.json')\n",
    "            with open(fname, 'w+') as outfile:  \n",
    "                json.dump(info_dict, outfile)\n",
    "        \n",
    "        if save_csp_patterns:\n",
    "            sub_patterns_ = np.asarray(tf_patterns_list)\n",
    "            fpath = op.join(path_save, 'patterns')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'patterns_per_sub.npy')\n",
    "            np.save(fname, sub_patterns_)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', centered_w_times)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freq_ranges)\n",
    "            del(fpath, fname)\n",
    "        \n",
    "        \n",
    "        if save_scores:\n",
    "            sub_scores_ = np.asarray(tf_scores_list)\n",
    "            fpath = op.join(path_save, 'scores')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "            np.save(fname, sub_scores_)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', centered_w_times)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freq_ranges)\n",
    "            del(fpath, fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return tf_scores_list, centered_w_times\n",
    "\n",
    "\n",
    "def load_scores_decod_tfr(conditions, part_epo='stimon', signaltype='collapsed'):\n",
    "    \"\"\"Load decoding results from disc.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conditions : list\n",
    "        List of strings containing the classes of the classification. \n",
    "    part_epo : str, optional\n",
    "        Part of the epoch. One of: 'fulllength', 'cue', 'stimon' (default is 'stimon').\n",
    "    signaltype: str\n",
    "        Processing state of the sensor signal. One of: 'collapsed': electrode positions flipped for cue left trials\n",
    "                                                       'uncollapsed': normal electrode positions,\n",
    "                                                       'difference': difference signal: contra minus ipsilateral\n",
    "                                                       (default is 'collapsed'.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results: ndarray \n",
    "        Array with decoding results (subjects x freqs x times)\n",
    "    times: array, 1d\n",
    "    freqs: array, 1d\n",
    "    \"\"\"\n",
    "    \n",
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    fpath = op.join(config.path_decod_tfr, part_epo, signaltype, contrast_str, 'scores')\n",
    "    fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "    res = np.load(fname)\n",
    "    times = np.load(fname[:-4] + '__times.npy')\n",
    "    freqs = np.load(fname[:-4] + '__freqs.npy')\n",
    "    return(res, times, freqs)\n",
    "\n",
    "\n",
    "def plot_decod_image_tfr(scores, conditions, times, freqs, ax=None):\n",
    "    \"\"\"Plot a heatmap with decoding accuracy over time and frequency. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores : ndarray, 2d\n",
    "        2d array with decoding results (freqs x timepoints)\n",
    "    conditions : list\n",
    "        List of strings containing the classes of the classification. \n",
    "    times: array, 1d\n",
    "        Timepoints\n",
    "    freqs: array, 1d\n",
    "        Frequencies \n",
    "    ax: axis, optional\n",
    "        Axis to plot into.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image\n",
    "        AxisImage\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    dx = np.diff(times)[0] / 2\n",
    "    dy = 0 #np.diff(freqs)[0] / 2\n",
    "    extent = [times.min()-dx, times.max()+dx,\n",
    "              freqs.min()-dy, freqs.max()+dy]             \n",
    "    image = ax.imshow(scores, origin='lower', cmap='Greens', aspect='auto', extent=extent)\n",
    "    ax.set_yticks([f for frange in freqs for f in frange])\n",
    "    ax.set_ylabel('frequency (Hz)')\n",
    "    return(image)\n",
    "\n",
    "\n",
    "def plot_score_ts(scores_df, plt_dict, color, ax=None, n_boot=1000):\n",
    "    \"\"\"Plot the decoding scores as timeseries line plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores_df : DataFrame \n",
    "        Data frame containing accuracies per time point in epoch. Long format. \n",
    "        Needed columns: 'time',\n",
    "                        'score'\n",
    "    plt_dict: dict\n",
    "        Dict containing info relevant for plotting. \n",
    "        Entries needed: 't_stimon': relative time of stimulus onset\n",
    "                        'xmin': minimal time to be plotted\n",
    "                        'xmax': maximal time to be plotted\n",
    "    color: str\n",
    "        A single color string referred to by name, RGB or RGBA code,\n",
    "        for instance ‘red’ or ‘#a98d19’.    \n",
    "    ax: axis, optional\n",
    "        Axis to plot into.\n",
    "    n_boot: int\n",
    "        Number of bootstrapping iterations for the CI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image\n",
    "        AxisImage\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    image = sns.lineplot(x='time', \n",
    "                 y='score', \n",
    "                 color = color,\n",
    "                 data=scores_df, \n",
    "                 n_boot=n_boot,  \n",
    "                 ax=ax)\n",
    "    ytick_range = ax.get_ylim()\n",
    "    ax.set(xlim=(plt_dict['xmin'], plt_dict['xmax']), ylim=ytick_range)\n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.axvspan(plt_dict['t_stimon'], plt_dict['t_stimon']+0.2, color='grey', alpha=0.3)\n",
    "    ax.axvspan(plt_dict['t_stimon']+ 2.2, plt_dict['t_stimon'] + 2.5, color='grey', alpha=0.3)\n",
    "    ax.vlines((plt_dict['t_stimon'], plt_dict['t_stimon']+0.2, plt_dict['t_stimon']+2.2),\n",
    "              ymin=ytick_range[0], ymax=ytick_range[1], \n",
    "              linestyles='dashed')\n",
    "    ax.hlines(0.5, xmin=plt_dict['xmin'], xmax=plt_dict['xmax'])\n",
    "    return(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "old_log_level = mne.set_log_level('WARNING', return_old_level=True)\n",
    "print(old_log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = np.setdiff1d(np.arange(1, 28), config.ids_missing_subjects +\n",
    "                        config.ids_excluded_subjects)               \n",
    "sub_list_str = ['VME_S%02d' % sub for sub in sub_list]\n",
    "\n",
    "cond_dict = {'Load': ['LoadLow', 'LoadHigh'], \n",
    "             'Ecc': ['EccS', 'EccM', 'EccL']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running VME_S01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-7b19051bb168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mres_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_list_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LoadLow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LoadHigh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mres_ecc_sl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_list_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'EccS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EccL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#res_ecc_ml = decode(sub_list_str, ['EccM', 'EccL'], config.event_dict, reps=5, overwrite=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-afa63d6b6cb5>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(sub_list_str, conditions, event_dict, reps, save_scores, save_csp_patterns, overwrite, part_epo, signaltype)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     tf_scores_tmp[rep, freq, t] = np.mean(cross_val_score(estimator=clf, X=X, y=y,\n\u001b[1;32m    227\u001b[0m                                                                           \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                                                                           n_jobs=-2), axis=0)\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msave_csp_patterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# get CSP patterns - fitted to all data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2019.03/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "res_load = decode(sub_list_str[:1], ['LoadLow', 'LoadHigh'], config.event_dict, reps=5, overwrite=True)\n",
    "res_ecc_sl = decode(sub_list_str, ['EccS', 'EccL'], config.event_dict, reps=5, overwrite=True)\n",
    "#res_ecc_ml = decode(sub_list_str, ['EccM', 'EccL'], config.event_dict, reps=5, overwrite=True)\n",
    "#res_ecc_sm = decode(sub_list_str, ['EccS', 'EccM'], config.event_dict, reps=5, overwrite=True)\n",
    "# res_load_eccL = decode(sub_list_str, ['LoadLowEccL', 'LoadHighEccL'], config.event_dict, reps=5, overwrite=True)\n",
    "# res_load_eccS = decode(sub_list_str, ['LoadLowEccS', 'LoadHighEccS'], config.event_dict, reps=5, overwrite=True)\n",
    "# res_load_eccM = decode(sub_list_str, ['LoadLowEccM', 'LoadHighEccM'], config.event_dict, reps=5, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
