{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test, f_mway_rm, f_threshold_mway_rm\n",
    "from mne.decoding import CSP\n",
    "from library import helpers, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_singletrialtfr(subID, condition, pwr_style='induced', \n",
    "                        part_epo='fulllength', baseline=None, mode=None): \n",
    "    fpath = op.join(config.path_tfrs, pwr_style, 'tfr_lists', part_epo)\n",
    "    fname = op.join(fpath, subID + '-collapsed-singletrialTFRs-tfr.h5')\n",
    "    tfr_ = mne.time_frequency.read_tfrs(fname)\n",
    "    for cond_tfr in range(len(tfr_)):\n",
    "        if cond_tfr.comment == condition:\n",
    "            tfr_selection = cond_tfr\n",
    "    \n",
    "    if baseline is not None:\n",
    "        tfr_selection.apply_baseline(baseline=baseline, mode=mode)\n",
    "    \n",
    "    return tfr_selection\n",
    "\n",
    "\n",
    "def batch_trials(epos, batch_size):\n",
    "    n_trials = len(epos)\n",
    "    n_batches = int(n_trials / batch_size)\n",
    "    rnd_seq = np.arange(n_trials)\n",
    "    np.random.shuffle(rnd_seq)\n",
    "    rnd_seq = rnd_seq[:n_batches * batch_size]\n",
    "    rnd_seq = rnd_seq.reshape(-1, batch_size)\n",
    "    batches = [epos[b].average() for b in rnd_seq]\n",
    "    return(batches)\n",
    "\n",
    "\n",
    "\n",
    "def avg_time(data, step=25, times=None):\n",
    "    orig_shape = data.shape\n",
    "    n_fill = step - (orig_shape[-1] % step)\n",
    "    fill_shape = np.asarray(orig_shape)\n",
    "    fill_shape[-1] = n_fill\n",
    "    fill = np.ones(fill_shape) * np.nan\n",
    "    data_f = np.concatenate([data, fill], axis=-1)\n",
    "    data_res = np.nanmean(data_f.reshape(*orig_shape[:-1], -1, step), axis=-1)\n",
    "\n",
    "    if times is not None:\n",
    "        f_times = np.r_[times, [np.nan] * n_fill]\n",
    "        n_times = np.nanmean(f_times.reshape(-1, step), axis=-1)\n",
    "        return data_res, n_times\n",
    "    else:\n",
    "        return data_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subID, part_epo, signaltype, conditions, event_dict,\n",
    "             batch_size=1, smooth_winsize=1):\n",
    "    tfr_dict = defaultdict(dict)\n",
    "    for cond in conditions:\n",
    "        tfr_dict[cond] = load_singletrialtfr(subID,\n",
    "                                             condition=cond,\n",
    "                                             pwr_style='induced',\n",
    "                                             part_epo=part_epo,\n",
    "                                             baseline=None,\n",
    "                                             mode=None)\n",
    "\n",
    "        times = tfr_dict[conditions[0]].times\n",
    "        freqs = tfr_dict[conditions[0]].freqs\n",
    "\n",
    "    # Setup data:\n",
    "    if batch_size > 1:\n",
    "        batches = defaultdict(list)\n",
    "        for cond in conditions:\n",
    "            batches[cond] = batch_trials(tfr_dict[cond], batch_size)\n",
    "            batches[cond] = np.asarray([b.data for b in batches[cond]])\n",
    "\n",
    "        X = np.concatenate([batches[cond].data for cond in conditions], axis=0)\n",
    "        n_ = {cond: batches[cond].shape[0] for cond in conditions}\n",
    "\n",
    "    else:\n",
    "        X = mne.concatenate_epochs([tfr_dict[cond] for cond in conditions])\n",
    "        X = X.data\n",
    "        n_ = {cond: len(tfr_dict[cond]) for cond in conditions}\n",
    "\n",
    "    if smooth_winsize > 1:\n",
    "        X, times_n = avg_time(X, smooth_winsize, times=times)\n",
    "    else:\n",
    "        times_n = times\n",
    "\n",
    "    y = np.r_[np.zeros(n_[conditions[0]]),\n",
    "              np.concatenate([(np.ones(n_[conditions[i]]) * i)\n",
    "                              for i in np.arange(1, len(conditions))])]\n",
    "\n",
    "    return X, y, times_n, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode(sub_list_str, conditions, part_epo='fulllength', signaltype='collapsed', freqs_decod='all',\n",
    "           event_dict=config.event_dict, n_rep_sub=100, shuffle_labels=False,\n",
    "           batch_size=1, smooth_winsize=1, save_single_rep_scores=False,\n",
    "           save_scores=True, save_patterns=False):\n",
    "\n",
    "    contrast_str = '_vs_'.join(conditions)\n",
    "    scoring = 'accuracy'\n",
    "    cv_folds = 5\n",
    "\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        LinearModel(LogisticRegression(solver='liblinear',\n",
    "                                                       penalty='l2',\n",
    "                                                       random_state=42,\n",
    "                                                       verbose=False)))\n",
    "\n",
    "    se = SlidingEstimator(clf,\n",
    "                          scoring=scoring,\n",
    "                          n_jobs=-2,\n",
    "                          verbose=0)\n",
    "\n",
    "    sub_scores = list()\n",
    "    sub_scores_per_rep = list()\n",
    "    sub_coef = list()\n",
    "    times_n = list()\n",
    "\n",
    "    for sub in sub_list_str:\n",
    "        print(f'### RUNING SUBJECT {sub}')\n",
    "        all_scores = list()\n",
    "        all_coef = list()\n",
    "        for i in np.arange(n_rep_sub):\n",
    "            X_allfreqs, y, times_n, freqs = get_data(sub,\n",
    "                                                    part_epo=part_epo,\n",
    "                                                    signaltype=signaltype,\n",
    "                                                    conditions=conditions,\n",
    "                                                    event_dict=event_dict,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    smooth_winsize=smooth_winsize)\n",
    "            if freqs_decod == 'all':\n",
    "                freqs_select = freqs\n",
    "            else:\n",
    "                freqs_select = [f for f in freqs_decod if f in freqs]\n",
    "                if len(freqs_select) < len(freqs_decod):\n",
    "                    f_not_found = [f for f in freqs_decod if f not in freqs]\n",
    "                    ending = 'y' if (len(f_not_found) == 1) else 'ies'\n",
    "                    raise ValueError(f'Frequenc{ending} not present in data: {f_not_found}')\n",
    "            if shuffle_labels:\n",
    "                np.random.shuffle(y)\n",
    "            for i in np.unique(y):\n",
    "                print(f'Size of class {i}: {np.sum(y == i)}\\n')\n",
    "            \n",
    "            scores_per_freq = np.zeros((len(freqs_select), len(times_n)))\n",
    "            coefs_per_freq = np.zeros((len(freqs_select), *X_allfreqs.shape[-2:]))\n",
    "            for idx, freq in enumerate(freqs_select):\n",
    "                 \n",
    "                 freq_idx = list(freqs).index(freq)\n",
    "                 X = X_allfreqs[:,:,freq_idx,:]\n",
    "                 scores = cross_val_multiscore(se, X=X, y=y, cv=cv_folds, verbose=0)\n",
    "                 scores = np.mean(scores, axis=0)\n",
    "                 scores_per_freq[idx, :] = scores\n",
    "\n",
    "                 se.fit(X, y)\n",
    "                 coef = get_coef(se, 'patterns_', inverse_transform=True)\n",
    "                 coefs_per_freq[idx, :, :] = coef\n",
    "                 \n",
    "            all_scores.append(scores_per_freq)\n",
    "            all_coef.append(coef)\n",
    "\n",
    "        sub_scores.append(np.asarray(all_scores).mean(axis=0))\n",
    "        sub_coef.append(np.asarray(all_coef).mean(axis=0))\n",
    "\n",
    "        # save shizzle:\n",
    "#         if save_single_rep_scores:\n",
    "#             if len(sub_scores_per_rep) == 0:\n",
    "#                 sub_scores_per_rep = np.asarray(all_scores)\n",
    "#             else:\n",
    "#                 sub_scores_per_rep = np.concatenate([sub_scores_per_rep,\n",
    "#                                                     np.asarray(all_scores)],\n",
    "#                                                     axis=0)\n",
    "\n",
    "#             fpath = op.join(config.path_decod_temp, contrast_str, 'single_rep_data')\n",
    "#             helpers.chkmk_dir(fpath)\n",
    "#             fname = op.join(fpath,\n",
    "#                             f'reps{n_rep_sub}_' \\\n",
    "#                             f'swin{smooth_winsize}_batchs{batch_size}.npy')\n",
    "#             np.save(fname, sub_scores_per_rep)\n",
    "#             np.save(fname[:-4] + '__times' + '.npy', times_n)\n",
    "#             del(fpath, fname)\n",
    "                 \n",
    "        # save info:\n",
    "        if (save_scores or save_patterns):\n",
    "            completed_subs.append(subID)\n",
    "            info_dict = {'subs': completed_subs,\n",
    "                         'freqs': freqs,\n",
    "                         'cv_folds': cv_folds, \n",
    "                         'reps': n_rep_sub,\n",
    "                         'batch_size': batch_size, \n",
    "                         'smooth_winsize': smooth_winsize, \n",
    "                         'scoring': scoring}\n",
    "            if len(sub_list_str) > 1:\n",
    "                 sub_folder = '-'.join(sub_list_str[0], sub_list_str[-1])\n",
    "            else:\n",
    "                 sub_folder = sub_list_str[0]\n",
    "                 \n",
    "            fpath = op.join(config.path_decod_tfr, 'wavelet', part_epo, signaltype, contrast_str, sub_folder)\n",
    "            if (op.exists(fpath) and not overwrite):\n",
    "                path_save = op.join(config.path_decod_tfr, 'wavelet', part_epo, signaltype, contrast_str, \n",
    "                                    sub_folder + datetime_str)\n",
    "            else:\n",
    "                path_save = fpath\n",
    "            helpers.chkmk_dir(path_save)\n",
    "            fname = op.join(path_save, 'info.json')\n",
    "            with open(fname, 'w+') as outfile:  \n",
    "                json.dump(info_dict, outfile)\n",
    "                 \n",
    "                 \n",
    "        # save accuracies:\n",
    "        if save_scores:\n",
    "            sub_scores_ = np.asarray(sub_scores)\n",
    "            fpath = op.join(path_save, 'scores')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'scores_per_sub.npy')\n",
    "            np.save(fname, sub_scores_)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', times_n)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freqs_select)\n",
    "            del(fpath, fname)\n",
    "\n",
    "\n",
    "        # save patterns:\n",
    "        if save_patterns:\n",
    "            sub_patterns = np.asarray(sub_coef)\n",
    "            fpath = op.join(path_save, 'patterns')\n",
    "            helpers.chkmk_dir(fpath)\n",
    "            fname = op.join(fpath, 'patterns_per_sub.npy')\n",
    "            np.save(fname, sub_patterns)\n",
    "            np.save(fname[:-4] + '__times' + '.npy', times_n)\n",
    "            np.save(fname[:-4] + '__freqs' + '.npy', freqs_select)\n",
    "            del(fpath, fname)\n",
    "                 \n",
    "    return sub_scores, sub_coef, times_n, freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
